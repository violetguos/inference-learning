{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logLearningRate -6.142641725270684\n",
      "learningRate 0.0021492384148\n",
      "numLayers 3\n",
      "numHiddenUnits 202\n",
      "logWeightedDecay -6.221198129637846\n",
      "weightedDecay 0.00198686327084\n",
      "dropOut 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:149: DeprecationWarning: This function is deprecated. Please call randint(1, 5 + 1) instead\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:151: DeprecationWarning: This function is deprecated. Please call randint(100, 500 + 1) instead\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:157: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class neuralNetwork:\n",
    "    \n",
    "    def __init__(self, _numLayer, _currNumUnit):\n",
    "        self.numLayer = _numLayer\n",
    "        self.currNumUnit = _currNumUnit\n",
    "        \n",
    "\n",
    "    def buildLayer(self, _inputTensor, _numUnits):\n",
    "        '''\n",
    "        input:\n",
    "            _inputTensor S = theta(Xprev)from the prev layer\n",
    "            _numUnits is the num of neurons in this layer\n",
    "    \n",
    "        intermediate xavierInit:\n",
    "            W is initialized as Xavier\n",
    "            W is input.shape[1] by num units\n",
    "    \n",
    "        output:\n",
    "        weighted sum of inputs\n",
    "    \n",
    "        '''\n",
    "    \n",
    "        # zero mean independent Gaussians whose variance is 3/(#input + #outputs)\n",
    "\n",
    "    \n",
    "        dim1 = _inputTensor.get_shape().as_list()[1]\n",
    "        #Xavier\n",
    "        #W = tf.get_variable(\"W\", shape = [dim1, _numUnits], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        variance = 3.0 / (dim1 + _numUnits)\n",
    "        W = tf.variable(tf.truncated_normal(shape = [dim1, _numUnits],  stddev = math.sqrt(variance)))\n",
    "        b = tf.Variable(0.0, name='biases')\n",
    "        #print(\"W\", W)\n",
    "        X = tf.matmul(tf.transpose(W), tf.cast(_inputTensor, dtype = tf.float_32))\n",
    "        return X\n",
    "    \n",
    "\n",
    "    def buildNet(self, _data, _numUnits):\n",
    "        '''\n",
    "        input: \n",
    "            number of hidden units\n",
    "            data\n",
    "        output:\n",
    "            predicted labels\n",
    "        '''\n",
    "        S_prev = tf.convert_to_tensor(_data)\n",
    "        for i in self.currNumUnit:              \n",
    "            S_curr = buildLayer(S_prev, numUnits)\n",
    "            #S is passed to relu already\n",
    "            S_prev = S_curr\n",
    "                      \n",
    "        #calculate error\n",
    "        #gradient descent\n",
    "    \n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "class loadData:\n",
    "    def __init__(self):\n",
    "        self.flatten = True\n",
    "        self.addOnes = False\n",
    "        \n",
    "        self.data_path = '/Users/vikuo/Documents/GitHub/ece521/assi/A3/notMNIST.npz'\n",
    "    def arrFlatten(self, arr):\n",
    "        '''\n",
    "        type np array\n",
    "        '''\n",
    "        dataDim1, dum1, dum2 = arr.shape\n",
    "        dum_sq = dum1 * dum2\n",
    "        arr = np.reshape(arr, [ dataDim1 ,dum_sq ])\n",
    "        return arr   \n",
    "    def convertTarget(self, targetValues):\n",
    "        numClasses = np.max(targetValues) + 1\n",
    "        return np.eye(numClasses)[targetValues]\n",
    "\n",
    "    def loadNotMnits(self):\n",
    "        with np.load(self.data_path) as data:\n",
    "            Data, Target = data [\"images\"], data[\"labels\"]\n",
    "            np.random.seed(521)\n",
    "            randIndx = np.arange(len(Data))\n",
    "            np.random.shuffle(randIndx)\n",
    "            Data = Data[randIndx]/255.\n",
    "            \n",
    "            if self.flatten:\n",
    "                Data = self.arrFlatten(Data)\n",
    "            \n",
    "            Target = Target[randIndx]\n",
    "            trainData, trainTarget = Data[:15000], Target[:15000]\n",
    "            validData, validTarget = Data[15000:16000], Target[15000:16000]\n",
    "            testData, testTarget = Data[16000:], Target[16000:]\n",
    "            \n",
    "            trainTarget = self.convertTarget(trainTarget)\n",
    "            validTarget = self.convertTarget(validTarget)\n",
    "            testTarget = self.convertTarget(testTarget)\n",
    " \n",
    "        return trainData, trainTarget, validData, validTarget, testData, testTarget\n",
    "\n",
    "class BatchSampler(object):\n",
    "    '''\n",
    "    A (very) simple wrapper to randomly sample batches without replacement.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, data, targets, batch_size):\n",
    "        self.num_points = data.shape[0]\n",
    "        self.features = data.shape[1]\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.batch_size = batch_size\n",
    "        self.indices = np.arange(self.num_points)\n",
    "\n",
    "    def random_batch_indices(self, m=None):\n",
    "        if m is None:\n",
    "            indices = np.random.choice(self.indices, self.batch_size, replace=False)\n",
    "        else:\n",
    "            indices = np.random.choice(self.indices, m, replace=False)\n",
    "        return indices \n",
    "\n",
    "    def get_batch(self, m=None):\n",
    "        '''\n",
    "        Get a random batch without replacement from the dataset.\n",
    "        If m is given the batch will be of size m. \n",
    "        Otherwise will default to the class initialized value.\n",
    "        '''\n",
    "        indices = self.random_batch_indices(m)\n",
    "        X_batch = np.take(self.data, indices, 0)\n",
    "        y_batch = self.targets[indices]\n",
    "        return X_batch, y_batch\n",
    "\n",
    "def hyperParamGen():\n",
    "    #random sampes using numpy\n",
    "    logLearningRate = np.random.uniform(-7.5, -4.5)\n",
    "    print(\"logLearningRate\", logLearningRate)\n",
    "    learningRate = np.exp(logLearningRate)\n",
    "    print(\"learningRate\", learningRate)\n",
    "    numLayers = np.random.random_integers(1, 5)\n",
    "    print(\"numLayers\", numLayers)\n",
    "    numHiddenUnits = np.random.random_integers(100, 500)\n",
    "    print(\"numHiddenUnits\", numHiddenUnits)\n",
    "    logWeightedDecay = np.random.uniform(-9, -6)\n",
    "    print(\"logWeightedDecay\", logWeightedDecay)\n",
    "    weightedDecay = np.exp(logWeightedDecay)\n",
    "    print(\"weightedDecay\", weightedDecay)\n",
    "    dropOut = np.random.random_integers(0, 1) # 0 or 1\n",
    "    print(\"dropOut\", dropOut)\n",
    "    \n",
    "    return learningRate, numLayers, numHiddenUnits, weightedDecay, dropOut\n",
    "    \n",
    "if __name__ == '__main__':  \n",
    "\n",
    "\n",
    "    #tf.reset_default_graph()\n",
    "    #init = tf.global_variables_initializer()\n",
    "    #sess = tf.InteractiveSession()\n",
    "    #sess.run(init)\n",
    "    \n",
    "                      \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
