{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******q1 part 1********\n",
      "init layer [5, 10]\n",
      "W 784 5\n",
      "X shape [None, 784]\n",
      "X in layer Tensor(\"add:0\", shape=(?, 5), dtype=float32)\n",
      "X_curr Tensor(\"add:0\", shape=(?, 5), dtype=float32)\n",
      "W 5 10\n",
      "X shape [None, 5]\n",
      "X in layer Tensor(\"add_1:0\", shape=(?, 10), dtype=float32)\n",
      "X_curr Tensor(\"add_1:0\", shape=(?, 10), dtype=float32)\n",
      "regTermsum 0\n",
      "crossEntropyError Curr Tensor(\"Mean_2:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Input 'y' of 'Add' Op has type float32 that does not match type int32 of argument 'x'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    509\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[1;32m    511\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_TensorTensorConversionFunction\u001b[0;34m(t, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    773\u001b[0m         \u001b[0;34m\"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m         (dtype.name, t.dtype.name, str(t)))\n\u001b[0m\u001b[1;32m    775\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor conversion requested dtype int32 for Tensor with dtype float32: 'Tensor(\"Mean_2:0\", shape=(), dtype=float32)'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-233bebcf4e2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;31m# TODO: Plotting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0msingleLayerNet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneuralNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m     \u001b[0msingleLayerNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunPart1_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainTarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidTarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestTarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-233bebcf4e2b>\u001b[0m in \u001b[0;36mrunPart1_1\u001b[0;34m(self, trainData, trainTarget, validData, validTarget, testData, testTarget)\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m             \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrossEntropyErrorCurr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracyTerm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuildNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0minit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-233bebcf4e2b>\u001b[0m in \u001b[0;36mbuildNet\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"crossEntropyError Curr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrossEntropyErrorCurr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mtotalLoss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregTermSum\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mcrossEntropyErrorCurr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearningRate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m--> 183\u001b[0;31m         \"Add\", x=x, y=y, name=name)\n\u001b[0m\u001b[1;32m    184\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    544\u001b[0m                   \u001b[0;34m\"%s type %s of argument '%s'.\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m                   (prefix, dtypes.as_dtype(attrs[input_arg.type_attr]).name,\n\u001b[0;32m--> 546\u001b[0;31m                    inferred_from[input_arg.type_attr]))\n\u001b[0m\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m           \u001b[0mtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Input 'y' of 'Add' Op has type float32 that does not match type int32 of argument 'x'."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "\n",
    "def hyperParamGen():\n",
    "    #random sampes using numpy\n",
    "    logLearningRate = np.random.uniform(-7.5, -4.5)\n",
    "    print(\"logLearningRate\", logLearningRate)\n",
    "    learningRate = np.exp(logLearningRate)\n",
    "    print(\"learningRate\", learningRate)\n",
    "    numLayers = np.random.random_integers(1, 5)\n",
    "    print(\"numLayers\", numLayers)\n",
    "    numHiddenUnits = np.random.random_integers(100, 500)\n",
    "    print(\"numHiddenUnits\", numHiddenUnits)\n",
    "    logWeightedDecay = np.random.uniform(-9, -6)\n",
    "    print(\"logWeightedDecay\", logWeightedDecay)\n",
    "    weightedDecay = np.exp(logWeightedDecay)\n",
    "    print(\"weightedDecay\", weightedDecay)\n",
    "    dropOut = np.random.random_integers(0, 1) # 0 or 1\n",
    "    print(\"dropOut\", dropOut)\n",
    "    \n",
    "    return learningRate, numLayers, numHiddenUnits, weightedDecay, dropOut\n",
    "\n",
    "def convertTarget(targetValues):\n",
    "    numClasses = np.max(targetValues) + 1\n",
    "    return np.eye(numClasses)[targetValues]\n",
    "\n",
    "class loadData:\n",
    "    def __init__(self):\n",
    "        self.flatten = True\n",
    "        self.addOnes = False\n",
    "        \n",
    "        self.data_path = '/Users/vikuo/Documents/GitHub/ece521/assi/A3/notMNIST.npz'\n",
    "    def arrFlatten(self, arr):\n",
    "        '''\n",
    "        type np array\n",
    "        '''\n",
    "        dataDim1, dum1, dum2 = arr.shape\n",
    "        dum_sq = dum1 * dum2\n",
    "        arr = np.reshape(arr, [ dataDim1 ,dum_sq ])\n",
    "        return arr   \n",
    "    '''\n",
    "    def convertTarget(self, targetValues):\n",
    "        numClasses = np.max(targetValues) + 1\n",
    "        return np.eye(numClasses)[targetValues]\n",
    "    '''\n",
    "    def loadNumData(self):\n",
    "        with np.load(self.data_path) as data:\n",
    "            Data, Target = data [\"images\"], data[\"labels\"]\n",
    "            np.random.seed(521)\n",
    "            randIndx = np.arange(len(Data))\n",
    "            np.random.shuffle(randIndx)\n",
    "            Data = Data[randIndx]/255.\n",
    "            \n",
    "            if self.flatten:\n",
    "                Data = self.arrFlatten(Data)\n",
    "            \n",
    "            Target = Target[randIndx]\n",
    "            trainData, trainTarget = Data[:15000], Target[:15000]\n",
    "            validData, validTarget = Data[15000:16000], Target[15000:16000]\n",
    "            testData, testTarget = Data[16000:], Target[16000:]\n",
    "            \n",
    "            trainTarget = convertTarget(trainTarget)\n",
    "            validTarget = convertTarget(validTarget)\n",
    "            testTarget = convertTarget(testTarget)\n",
    " \n",
    "        return trainData, trainTarget, validData, validTarget, testData, testTarget\n",
    "\n",
    "class BatchSampler(object):\n",
    "    '''\n",
    "    A (very) simple wrapper to randomly sample batches without replacement.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, data, targets, batch_size):\n",
    "        self.num_points = data.shape[0]\n",
    "        self.features = data.shape[1]\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.batch_size = batch_size\n",
    "        self.indices = np.arange(self.num_points)\n",
    "\n",
    "    def random_batch_indices(self, m=None):\n",
    "        if m is None:\n",
    "            indices = np.random.choice(self.indices, self.batch_size, replace=False)\n",
    "        else:\n",
    "            indices = np.random.choice(self.indices, m, replace=False)\n",
    "        return indices \n",
    "\n",
    "    def get_batch(self, m=None):\n",
    "        '''\n",
    "        Get a random batch without replacement from the dataset.\n",
    "        If m is given the batch will be of size m. \n",
    "        Otherwise will default to the class initialized value.\n",
    "        '''\n",
    "        indices = self.random_batch_indices(m)\n",
    "        X_batch = np.take(self.data, indices, 0)\n",
    "        y_batch = self.targets[indices]\n",
    "        return X_batch, y_batch\n",
    "\n",
    "\n",
    "class neuralNetwork:\n",
    "    # these are for testing only\n",
    "    def __init__(self, _learningRate = 0.05, _learningRateArr = [0.05], \n",
    "                 _numLayers = [5], _weightedDecay = 0.0003, _dropOut = 0, _numEpoch = 3):\n",
    "        # learningRate, numLayers, numHiddenUnits, weightedDecay, dropOut\n",
    "        self.learningRate = _learningRate\n",
    "        self.learningRateArr = _learningRateArr\n",
    "        self.numLayers = _numLayers # number of units in each layer\n",
    "        self.numLayers.append(10)\n",
    "        print(\"init layer\", self.numLayers)\n",
    "        self.weightedDecay = _weightedDecay\n",
    "        self.dropOut = _dropOut\n",
    "        self.dropOutProb = 0.5\n",
    "        self.numEpoch = _numEpoch\n",
    "        \n",
    "        \n",
    "        # default, no arg taken\n",
    "        self.numPixel = 784 \n",
    "        self.numClass = 10\n",
    "        self.batchSize = 500\n",
    "        \n",
    "    def buildLayer(self, _inputTensor, _numUnits):\n",
    "        '''\n",
    "        input:\n",
    "            #feed# _inputTensor S = theta(Xprev)from the prev layer\n",
    "            _numUnits is the num of neurons in this layer\n",
    "    \n",
    "        intermediate xavierInit:\n",
    "            W is initialized as Xavier\n",
    "            W is input.shape[1] by num units\n",
    "    \n",
    "        output:\n",
    "        weighted sum of inputs\n",
    "    \n",
    "        '''\n",
    "        # zero mean independent Gaussians whose variance is 3/(#input + #outputs)  \n",
    "        dim1 = _inputTensor.get_shape().as_list()[1]\n",
    "        \n",
    "\n",
    "        \n",
    "        #Xavier\n",
    "        #W = tf.get_variable(\"W\", shape = [dim1, _numUnits], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        variance = 3.0 / (dim1 + _numUnits)\n",
    "        W = tf.Variable(tf.truncated_normal(shape = [dim1, _numUnits],  stddev = math.sqrt(variance)))\n",
    "        #b = tf.Variable(0.0, name='biases')\n",
    "        b = tf.Variable(tf.zeros([_numUnits]), name = 'biases')\n",
    "\n",
    "        \n",
    "        print(\"W\", dim1, _numUnits)\n",
    "        print(\"X shape\", _inputTensor.get_shape().as_list())\n",
    "        X = tf.matmul(tf.cast(_inputTensor, dtype = tf.float32), W) + b\n",
    "    \n",
    "        #X = tf.add(X, b)\n",
    "        print(\"X in layer\", X)\n",
    "        regTerm = tf.multiply( tf.constant(0.50, dtype = tf.float32),\\\n",
    "                        tf.multiply(tf.constant(self.weightedDecay,dtype = tf.float32), tf.reduce_mean(tf.square(W))))\n",
    "        \n",
    "        tf.add_to_collection(\"layerW\", W)\n",
    "        tf.add_to_collection(\"layerReg\", regTerm)\n",
    "\n",
    "        return X\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "    def accuracy(self, y_hat, target):\n",
    "        #TAKEN FROM last assignment\n",
    "        \n",
    "        target = tf.cast(target, dtype = tf.float32)\n",
    "        correctCases = tf.equal(tf.argmax(y_hat, 1), tf.argmax(target, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correctCases, dtype=\"float\"))\n",
    "        return accuracy #.eval()\n",
    "    \n",
    "    def classificationError(self, y_hat, target):\n",
    "        target = tf.cast(target, dtype = tf.float32)\n",
    "        correctCases = tf.equal(tf.argmax(y_hat, 1), tf.argmax(target, 1))\n",
    "        \n",
    "        error = 1 - tf.reduce_mean(tf.cast(correctCases, dtype=\"float\"))\n",
    "        return error\n",
    "\n",
    "    \n",
    "    def buildNet(self):\n",
    "        '''\n",
    "        input: \n",
    "            number of hidden units #in the class def\n",
    "            data #feed\n",
    "        output:\n",
    "            predicted labels\n",
    "        '''\n",
    "                \n",
    "        X = tf.placeholder(tf.float32, shape=[None, self.numPixel], name='dataX')\n",
    "        y_target = tf.placeholder(tf.float32, shape=[None, self.numClass], name='targetY')\n",
    "\n",
    "        X_prev = X #tf.convert_to_tensor(X)\n",
    "        for numUnits in self.numLayers: #numLayers is an array of num hidden units            \n",
    "            X_curr = self.buildLayer(X_prev, numUnits)\n",
    "            print(\"X_curr\", X_curr)\n",
    "            S_curr = tf.nn.relu(X_curr)\n",
    "            X_prev = S_curr\n",
    "            if self.dropOut:\n",
    "                X_prev = tf.nn.dropout(X_prev, self.dropOutProb)\n",
    "        \n",
    "        y_hat = X_prev\n",
    "        \n",
    "        crossEntropyErrorCurr = tf.reduce_mean(\n",
    "                tf.nn.softmax_cross_entropy_with_logits(logits = y_hat, labels = y_target))\n",
    "        \n",
    "        regTermSum = sum(tf.get_collection(\"regTerm\"))\n",
    "        regTermSum = tf.cast(regTermSum, dtype = tf.float32)\n",
    "        print(\"regTermsum\", regTermSum)\n",
    "        print(\"crossEntropyError Curr\", crossEntropyErrorCurr)\n",
    "        \n",
    "        totalLoss = tf.add(regTermSum , crossEntropyErrorCurr)\n",
    "        \n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate = self.learningRate)\n",
    "        train = optimizer.minimize(loss=totalLoss)\n",
    "        accuracyTerm = self.accuracy(y_hat, y_target)\n",
    "        \n",
    "        W = tf.get_collection(\"layerW\")\n",
    "        \n",
    "        return W, X, y_hat, y_target, crossEntropyErrorCurr, accuracyTerm, train   #final prediction\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "    def plotFig(self, _dim, y , addInfo, title=\"default\", xLabel=\"iter/epoch\", yLabel=\"yLabel\", plotLabel =\"plotLabel\", _num =1 ):\n",
    "        x = np.linspace(0, _dim, num=_dim)\n",
    "        y = np.array(y)\n",
    "        print(\"$$$$$$$$$$$$$$$ in plot fig$$$$$$$$$$$$$$$$$\")\n",
    "        print(y.shape)\n",
    "        plt.figure(_num)\n",
    "        plt.title(title)\n",
    "        plt.xlabel(xLabel)\n",
    "        plt.ylabel(yLabel)\n",
    "        for i in range(y.shape[0]):\n",
    "            #print(\"x\", x)\n",
    "            #print(\"y\", y[i])\n",
    "            plt.plot(x, y[i], label = plotLabel + str(addInfo[i]))\n",
    "        \n",
    "        plt.legend()\n",
    "        plt.savefig( title + str(_num) + \".png\")\n",
    "        plt.close()\n",
    "        plt.clf()\n",
    "        \n",
    "    def runPart1_1(self, trainData, trainTarget, validData, validTarget,testData, testTarget):\n",
    "        '''\n",
    "        input: data\n",
    "                3 learning rates to try\n",
    "        output:\n",
    "            classification error plot\n",
    "            cross entropy loss plot\n",
    "        '''\n",
    "        \n",
    "        trainLossArr= []\n",
    "        mseLossArr = []\n",
    "        trainAccuArr = []\n",
    "        \n",
    "        validLossArr = []\n",
    "        validAccuArr = []\n",
    "        \n",
    "        \n",
    "        for learningRate in self.learningRateArr:\n",
    "            currEpoch = 0\n",
    "\n",
    "            \n",
    "            trainLossL = []\n",
    "            mseLossL = []\n",
    "            trainAccuL = []\n",
    "            \n",
    "            validLossL =[]\n",
    "            validAccuL = []\n",
    "            tf.reset_default_graph()\n",
    "            \n",
    "            W, X, y_hat, y_target, crossEntropyErrorCurr, accuracyTerm, train = self.buildNet()\n",
    "            \n",
    "            init = tf.global_variables_initializer()\n",
    "            sess = tf.InteractiveSession()\n",
    "            sess.run(init)\n",
    "            initialW = sess.run(W)  \n",
    "            \n",
    "            print(\"learningrate = \", learningRate)\n",
    "            trainBatchSampler = BatchSampler(trainData, trainTarget, self.batchSize)\n",
    "        \n",
    "            while currEpoch<= self.numEpoch:\n",
    "                dataBatch, targetBatch = trainBatchSampler.get_batch()\n",
    "                currentW, errTrain, accuracyTrain, y_predict, trainModel = \\\n",
    "                        sess.run([W, crossEntropyErrorCurr, accuracyTerm, y_hat, train], feed_dict={X: dataBatch, y_target: targetBatch})\n",
    "\n",
    "                print(\"currEpoch\", currEpoch, accuracyTrain)\n",
    "                currEpoch = currEpoch + 1\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':  \n",
    "\n",
    "    dataLoader = loadData()\n",
    " \n",
    "    trainData, trainTarget, validData, validTarget,testData, testTarget = dataLoader.loadNumData()\n",
    "    \n",
    "    print(\"*******q1 part 1********\")\n",
    "    learningRates = [0.001, 0.05, 0.01]\n",
    "    lambdaReg = 0.0003\n",
    "    # TODO: Plotting\n",
    "    singleLayerNet = neuralNetwork()\n",
    "    singleLayerNet.runPart1_1(trainData, trainTarget, validData, validTarget,testData, testTarget)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "                      \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
