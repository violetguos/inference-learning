{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from __future__ import print_function\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A1 Q1\n",
    "Euclidean distance function, vectorized    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def euclideanDistance(x, z):\n",
    "    '''\n",
    "    We vectorized the operation with matrix operations\n",
    "    the ||x - z ||^2 is = Sum(x - z)^2 = Sum from 1 to D\n",
    "    of (x^2 - 2xz + z^2)\n",
    "    \n",
    "    x^2 = x^T times x\n",
    "    z^2 = z^T times z\n",
    "    we can find the sum of each row by using the reduce sum function\n",
    "    \n",
    "    sum of -2xz \n",
    "    we can use matrix multiplication, x times z^T to obtain xz,\n",
    "    then multiply by -2\n",
    "    '''\n",
    "    n1 = x.shape[0]\n",
    "    n2 = z.shape[0]    \n",
    "    \n",
    "    x_squared = tf.square(x)\n",
    "    z_squared = tf.square(z) #tf.matmul(z ,tf.transpose(z))\n",
    "    #print(\"x_squared.eval()\")\n",
    "    #print(x_squared.eval())\n",
    "    x_2_sum = tf.reduce_sum(x_squared, 1)\n",
    "    z_2_sum = tf.reduce_sum(z_squared, 1)\n",
    "    \n",
    "    x_2_sum = tf.transpose(x_2_sum)\n",
    "    z_2_sum = tf.transpose(z_2_sum)\n",
    "    #x_2_sum = tf.reshape(x_2_sum, [-1, 1])\n",
    "    #z_2_sum = tf.reshape(z_2_sum, [-1, 1])\n",
    "    #print(\"x_2_sum.eval()\")\n",
    "    #print(x_2_sum.eval())\n",
    "    \n",
    "    xz = tf.matmul(x, tf.transpose(z))\n",
    "    #print(xz.eval())\n",
    "    minus_2xz = tf.scalar_mul(-2, xz)\n",
    "    #print(minus_2xz.eval())\n",
    " \n",
    "    x_2_tile =tf.tile(tf.expand_dims(x_2_sum, 1), [1, n2])\n",
    "    z_2_tile = tf.tile(tf.expand_dims(z_2_sum ,1), [1, n1])\n",
    "    z_2_tile_T = tf.transpose(z_2_tile)\n",
    "    #print(x_2_tile.eval())\n",
    "    #print(z_2_tile_T.eval())\n",
    "    \n",
    "    result = x_2_tile + minus_2xz +z_2_tile_T\n",
    "    \n",
    "    return result\n",
    "\n",
    "\"\"\"VERIFIED\"\"\"\n",
    "\n",
    "def testi():\n",
    "    A = tf.constant([[1, 1], [2,2], [3, 3], [4,4]])\n",
    "    B = tf.constant([[1, 1], [2, 2],[3,3]])\n",
    "    res_mine = euclideanDistance(A, B)\n",
    "    \n",
    "    print(\"----my func----\")\n",
    "    print(res_mine.eval())\n",
    "    print(\"---diff square---\")\n",
    "    res_lib = PairwiseDistances(A, B)\n",
    "    print(res_lib.eval())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A1 Q2\n",
    "### part 1\n",
    "\n",
    "| x1^T | x2^T | .... |\n",
    "top k closest in x1^T indices are the neighbours\n",
    "\n",
    "\n",
    "yˆ(x∗) = YTr∗, where r∗ = [r1,...,rN],rn = 1/k\n",
    "0, otherwise.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given starter code\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# my code part1 responsibility\n",
    "def nearestIndices(_dist_mat, _k):\n",
    "    # with tf.Session() as sess:\n",
    "    #_dist_mat = tf.constant([ [4, 9], [16, 25] ], tf.int32)\n",
    "    print(\"our k value\", _k)\n",
    "    #print(\"dist mat shape\", _dist_mat.shape)\n",
    "    nearest_k_data, nearest_k_indices = tf.nn.top_k(tf.negative(_dist_mat), _k)\n",
    "       \n",
    "    #print(type(indices_arr))\n",
    "    return nearest_k_data, nearest_k_indices\n",
    "\n",
    "\n",
    "#unit testing\n",
    "#dist_mat = tf.constant([ 4, 9, 16, 25 ], tf.int32)\n",
    "#topk = nearestIndices(dist_mat, 2)\n",
    "#responsibility(topk, 2, 4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairDist(_data, _data1):\n",
    "    #TODO: what if no library function\n",
    "    data_t = tf.convert_to_tensor(_data)\n",
    "    data1_t = tf.convert_to_tensor(_data1)\n",
    "    dist = euclideanDistance(data_t, data1_t)\n",
    "    return dist\n",
    "  \n",
    "\n",
    "def knn(_trainData, _trainTarget, _new_data, _k):\n",
    "    '''\n",
    "    KNN using responsibility\n",
    "    '''\n",
    "    #nearest indices\n",
    "    dist_mat = pairDist( _new_data, _trainData )    \n",
    "    #dist_mat = tf.convert_to_tensor(dist_mat)\n",
    "    nearest_k, nearest_k_idx = nearestIndices(dist_mat, _k)\n",
    "    predict_res = tf.reduce_mean(tf.gather(_trainTarget, nearest_k_idx), 1)\n",
    "    #print(\"predict\", predict_res.eval())\n",
    "    return predict_res\n",
    "\n",
    "\n",
    "def knnVote(_trainData, _trainTarget, _new_data, _k):\n",
    "    '''\n",
    "    KNN using majority vote\n",
    "    '''\n",
    "    #nearest indices\n",
    "    dist_mat = pairDist( _new_data, _trainData )    \n",
    "    nearest_k, nearest_k_idx = nearestIndices(dist_mat, _k)\n",
    "    neighbours = tf.gather(_trainTarget, nearest_k_idx)\n",
    "    print(\"neibours index before\", neighbours)\n",
    "    \n",
    "    s1 = neighbours.shape[0]\n",
    "    n_unstack = tf.unstack(neighbours, axis = 1)\n",
    "    #print(\"n_unstack\", n_unstack)\n",
    "    print(\"neighbours after reshape\", neighbours)\n",
    "\n",
    "    nearest_k_y, idx, votes = [], [], []\n",
    "    predict_res = []\n",
    "    for i in n_unstack:\n",
    "        y, i, v = tf.unique_with_counts(i) \n",
    "        nearest_k_y.append(y)\n",
    "        idx.append(i)\n",
    "        votes.append(v)\n",
    "        predict_res.append(tf.argmax(v))\n",
    "        \n",
    "    #print(\"predict\", predict_res.eval())\n",
    "    return predict_res\n",
    "\n",
    "  \n",
    "\n",
    "#pairDist(testData) \n",
    "#pred_result = knn(testData, testTarget, _k = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plotResult(_trainData, _trainTarget):\n",
    "    X = np.linspace(0.0, 11.0, num = 100)[:, np.newaxis]\n",
    "    xTensor = tf.stack(X)\n",
    "    \n",
    "    num_neighbour_list = [1, 3, 5, 50]\n",
    "    for j in num_neighbour_list:\n",
    "        print(\"plot result\")\n",
    "        dist_mat = pairDist( X, _trainData ) \n",
    "        nearest_k, nearest_k_idx = nearestIndices(dist_mat, j)\n",
    "        predict_res = tf.reduce_mean(tf.gather(_trainTarget, nearest_k_idx), 1)\n",
    "\n",
    "        plt.figure()#(j+100)\n",
    "        plt.scatter(sessMain.run(_trainData), sessMain.run(_trainTarget))\n",
    "        plt.title(\"K = \" + str(j))\n",
    "        plt.plot(sessMain.run(xTensor), sessMain.run(predict_res))\n",
    "        \n",
    "        fileName = str(\"KNN\") + str(j) + str(\"trainingGraph.png\")\n",
    "        plt.savefig(fileName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testKValuesKNN(trainData, trainTarget, testData, testTarget):\n",
    "    num_neighbour_list = [1, 3, 5, 50]\n",
    "    loss_list = []\n",
    "\n",
    "    for j in num_neighbour_list:\n",
    "        print(\"j = \", j)\n",
    "        y_hat = knn(trainData, trainTarget, testData,  j)\n",
    "        #_y_hat = tf.transpose(_y_hat)\n",
    "        #mse_mat = euclideanDistance(_y_hat, _y) \n",
    "      \n",
    "        mse_mat = tf.square(tf.subtract(y_hat, testTarget))\n",
    "        loss = tf.reduce_mean(mse_mat)/2.0\n",
    "        print(\"neighbout = \" ,j)\n",
    "        loss_list.append(loss.eval())\n",
    "    return loss_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1():\n",
    "    np.random.seed(521)\n",
    "    Data = np.linspace(1.0 , 10.0 , num =100) [:, np. newaxis]\n",
    "    Target = np.sin( Data ) + 0.1 * np.power( Data , 2) \\\n",
    "         + 0.5 * np.random.randn(100 , 1)\n",
    "    randIdx = np.arange(100)\n",
    "    np.random.shuffle(randIdx)\n",
    "    trainData, trainTarget  = Data[randIdx[:80]], Target[randIdx[:80]]\n",
    "    validData, validTarget = Data[randIdx[80:90]], Target[randIdx[80:90]]\n",
    "    testData, testTarget = Data[randIdx[90:100]], Target[randIdx[90:100]]\n",
    "\n",
    "    # convert numpy array to tensors\n",
    "    trainData = tf.stack(trainData)\n",
    "    trainTarget = tf.stack(trainTarget)\n",
    "    testData = tf.stack(testData)\n",
    "    testTarget = tf.stack(testTarget)\n",
    "    validData = tf.stack(validData)\n",
    "    validtarget = tf.stack(validTarget)\n",
    "    \n",
    "    plotResult(trainData, trainTarget)\n",
    "    \n",
    "    loss_test = testKValuesKNN(trainData, trainTarget, testData, testTarget)\n",
    "    print(\"loss_test\", loss_test)\n",
    "    \n",
    "    loss_train = testKValuesKNN(trainData, trainTarget, trainData, trainTarget)\n",
    "    print(\"loss_train\" , loss_train)\n",
    "    \n",
    "    loss_valid = testKValuesKNN(trainData, trainTarget, validData, validTarget)\n",
    "    print(\"loss_valid\", loss_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss on KNN\n",
    "\n",
    "|k | 1 | 3 | 5| 50|\n",
    "|------|------|-----|-----|\n",
    "|test | 0.12799977712101845 | 0.14242504248546536 | 0.18633105926605592 | 0.70693467047889302 |\n",
    "|train | 0.0 | 0.10825207710580038 | 0.12183845521874122 | 1.2477892734500411 |\n",
    "|valid | 0.28807977607463453 | 0.30897640431136369 | 0.31043863052707066 | 1.2230445257949047 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_segmentation(data_path, target_path, task):\n",
    "    # task = 0 >> select the name ID targets for face recognition task\n",
    "    # task = 1 >> select the gender ID targets for gender recognition task data = np.load(data_path)/255\n",
    "    data = np.load(data_path)/255\n",
    "    data = np.reshape(data, [-1, 32*32])\n",
    "    target = np.load(target_path)\n",
    "    np.random.seed(45689)\n",
    "    rnd_idx = np.arange(np.shape(data)[0])\n",
    "    np.random.shuffle(rnd_idx)\n",
    "    trBatch = int(0.8*len(rnd_idx))\n",
    "    validBatch = int(0.1*len(rnd_idx))\n",
    "    trainData, validData, testData = data[rnd_idx[1:trBatch],:], \\\n",
    "                                   data[rnd_idx[trBatch+1:trBatch + validBatch],:],\\\n",
    "                                   data[rnd_idx[trBatch + validBatch+1:-1],:]\n",
    "    trainTarget, validTarget, testTarget = target[rnd_idx[1:trBatch], task], \\\n",
    "                              target[rnd_idx[trBatch+1:trBatch + validBatch], task],\\\n",
    "                              target[rnd_idx[trBatch + validBatch + 1:-1], task]\n",
    "    return trainData, validData, testData, trainTarget, validTarget, testTarget\n",
    "\n",
    "def rgb2gray(image):\n",
    "    return dot(image[...,:3], [0.299, 0.587, 0.114])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q2():\n",
    "    data_path = '/Users/vikuo/Documents/GitHub/ece521/assi/A1/data/data.npy'\n",
    "    target_path = '/Users/vikuo/Documents/GitHub/ece521/assi/A1/data/target.npy'\n",
    "    trainData, validData, testData, trainTarget, validTarget, testTarget = data_segmentation(data_path, target_path, 0)\n",
    "    \n",
    "    # convert numpy array to tensors\n",
    "    trainData = tf.stack(trainData)\n",
    "    trainTarget = tf.stack(trainTarget)\n",
    "    testData = tf.stack(testData)\n",
    "    testTarget = tf.stack(testTarget)\n",
    "    validData = tf.stack(validData)\n",
    "    validtarget = tf.stack(validTarget)\n",
    "    \n",
    "    loss_train = testQ2KNN(trainData, trainTarget, trainData, trainTarget)\n",
    "    print(\"loss train\", loss_train)\n",
    "    \n",
    "    loss_test = testQ2KNN(trainData, trainTarget, testData, testTarget)\n",
    "    print(\"loss test\", loss_test)\n",
    "    \n",
    "    loss_valid = testQ2KNN(trainData, trainTarget, testData, testTarget)\n",
    "    print(\"loss valid\", loss_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testQ2KNN(trainData, trainTarget, testData, testTarget):\n",
    "    num_neighbour_list = [1, 5, 10, 25, 50, 100, 200]\n",
    "    loss_list = []\n",
    "    for j in num_neighbour_list:\n",
    "        print(\"j = \", j)\n",
    "        y_hat = knnVote(trainData, trainTarget, testData,  j)\n",
    "        testTarget = tf.cast(testTarget, tf.int64)\n",
    "        print(testTarget)\n",
    "        mse_mat = tf.square(tf.subtract(y_hat, testTarget))\n",
    "        loss = tf.reduce_mean(mse_mat)#/2.0\n",
    "        print(\"div by 2!!!\", loss)\n",
    "        print(\"neighbout = \" ,j)\n",
    "        loss_list.append(loss.eval())\n",
    "    return loss_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j =  1\n",
      "our k value 1\n",
      "neibours index before Tensor(\"Gather_23:0\", shape=(747, 1), dtype=uint8)\n",
      "neighbours after reshape Tensor(\"Gather_23:0\", shape=(747, 1), dtype=uint8)\n",
      "Tensor(\"Cast_5:0\", shape=(747,), dtype=int64)\n",
      "div by 2!!! Tensor(\"Mean_3:0\", shape=(), dtype=int64)\n",
      "neighbout =  1\n",
      "j =  5\n",
      "our k value 5\n",
      "neibours index before Tensor(\"Gather_24:0\", shape=(747, 5), dtype=uint8)\n",
      "neighbours after reshape Tensor(\"Gather_24:0\", shape=(747, 5), dtype=uint8)\n",
      "Tensor(\"Cast_5:0\", shape=(747,), dtype=int64)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 5 and 747 for 'Sub_9' (op: 'Sub') with input shapes: [5], [747].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    685\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[1;32m    687\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 5 and 747 for 'Sub_9' (op: 'Sub') with input shapes: [5], [747].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-1da6e51c439f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#q1()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mq2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-157-9cfc69f8815d>\u001b[0m in \u001b[0;36mq2\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mvalidtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidTarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mloss_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestQ2KNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainTarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainTarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-158-c220f945df12>\u001b[0m in \u001b[0;36mtestQ2KNN\u001b[0;34m(trainData, trainTarget, testData, testTarget)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mtestTarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestTarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestTarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mmse_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestTarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#/2.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"div by 2!!!\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36msubtract\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36m_sub\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   4634\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4635\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 4636\u001b[0;31m         \"Sub\", x=x, y=y, name=name)\n\u001b[0m\u001b[1;32m   4637\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4638\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2956\u001b[0m         op_def=op_def)\n\u001b[1;32m   2957\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2958\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2959\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2207\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2209\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2210\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2211\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2159\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2161\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, require_shape_fn)\u001b[0m\n\u001b[1;32m    625\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    626\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                                   require_shape_fn)\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    689\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 5 and 747 for 'Sub_9' (op: 'Sub') with input shapes: [5], [747]."
     ]
    }
   ],
   "source": [
    "from scipy import spatial as sp\n",
    "from sklearn import metrics as skm\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    sessMain = tf.InteractiveSession()\n",
    "    sessMain.run(init)\n",
    "    #q1()\n",
    "\n",
    "    q2()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
