{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from __future__ import print_function\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A1 Q1\n",
    "Euclidean distance function, vectorized    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def euclideanDistance(x, z):\n",
    "    '''\n",
    "    We vectorized the operation with matrix operations\n",
    "    the ||x - z ||^2 is = Sum(x - z)^2 = Sum from 1 to D\n",
    "    of (x^2 - 2xz + z^2)\n",
    "    \n",
    "    x^2 = x^T times x\n",
    "    z^2 = z^T times z\n",
    "    we can find the sum of each row by using the reduce sum function\n",
    "    \n",
    "    sum of -2xz \n",
    "    we can use matrix multiplication, x times z^T to obtain xz,\n",
    "    then multiply by -2\n",
    "    '''\n",
    "    n1 = x.shape[0]\n",
    "    n2 = z.shape[0]    \n",
    "    \n",
    "    x_squared = tf.square(x)\n",
    "    z_squared = tf.square(z) #tf.matmul(z ,tf.transpose(z))\n",
    "    #print(\"x_squared.eval()\")\n",
    "    #print(x_squared.eval())\n",
    "    x_2_sum = tf.reduce_sum(x_squared, 1)\n",
    "    z_2_sum = tf.reduce_sum(z_squared, 1)\n",
    "    \n",
    "    x_2_sum = tf.transpose(x_2_sum)\n",
    "    z_2_sum = tf.transpose(z_2_sum)\n",
    "    #x_2_sum = tf.reshape(x_2_sum, [-1, 1])\n",
    "    #z_2_sum = tf.reshape(z_2_sum, [-1, 1])\n",
    "    #print(\"x_2_sum.eval()\")\n",
    "    #print(x_2_sum.eval())\n",
    "    \n",
    "    xz = tf.matmul(x, tf.transpose(z))\n",
    "    #print(xz.eval())\n",
    "    minus_2xz = tf.scalar_mul(-2, xz)\n",
    "    #print(minus_2xz.eval())\n",
    " \n",
    "    x_2_tile =tf.tile(tf.expand_dims(x_2_sum, 1), [1, n2])\n",
    "    z_2_tile = tf.tile(tf.expand_dims(z_2_sum ,1), [1, n1])\n",
    "    z_2_tile_T = tf.transpose(z_2_tile)\n",
    "    #print(x_2_tile.eval())\n",
    "    #print(z_2_tile_T.eval())\n",
    "    \n",
    "    result = x_2_tile + minus_2xz +z_2_tile_T\n",
    "    \n",
    "    return result\n",
    "\n",
    "\"\"\"VERIFIED\"\"\"\n",
    "\n",
    "def testi():\n",
    "    A = tf.constant([[1, 1], [2,2], [3, 3], [4,4]])\n",
    "    B = tf.constant([[1, 1], [2, 2],[3,3]])\n",
    "    res_mine = euclideanDistance(A, B)\n",
    "    \n",
    "    print(\"----my func----\")\n",
    "    print(res_mine.eval())\n",
    "    print(\"---diff square---\")\n",
    "    res_lib = PairwiseDistances(A, B)\n",
    "    print(res_lib.eval())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A1 Q2\n",
    "### part 1\n",
    "\n",
    "| x1^T | x2^T | .... |\n",
    "top k closest in x1^T indices are the neighbours\n",
    "\n",
    "\n",
    "yˆ(x∗) = YTr∗, where r∗ = [r1,...,rN],rn = 1/k\n",
    "0, otherwise.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given starter code\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# my code part1 responsibility\n",
    "def nearestIndices(_dist_mat, _k):\n",
    "    # with tf.Session() as sess:\n",
    "    #_dist_mat = tf.constant([ [4, 9], [16, 25] ], tf.int32)\n",
    "    print(\"our k value\", _k)\n",
    "    #print(\"dist mat shape\", _dist_mat.shape)\n",
    "    nearest_k_data, nearest_k_indices = tf.nn.top_k(tf.negative(_dist_mat), _k)\n",
    "       \n",
    "    #print(type(indices_arr))\n",
    "    return nearest_k_data, nearest_k_indices\n",
    "\n",
    "\n",
    "#unit testing\n",
    "#dist_mat = tf.constant([ 4, 9, 16, 25 ], tf.int32)\n",
    "#topk = nearestIndices(dist_mat, 2)\n",
    "#responsibility(topk, 2, 4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairDist(_data, _data1):\n",
    "    #TODO: what if no library function\n",
    "    data_t = tf.convert_to_tensor(_data)\n",
    "    data1_t = tf.convert_to_tensor(_data1)\n",
    "    #data_t = tf.cast(data_t, tf.float16)\n",
    "    #data1_t = tf.cast(data1_t, tf.float16)\n",
    "    dist = euclideanDistance(data_t, data1_t)\n",
    "    return dist\n",
    "  \n",
    "\n",
    "def knn(_trainData, _trainTarget, _new_data, _k):\n",
    "    '''\n",
    "    KNN using responsibility\n",
    "    '''\n",
    "    #nearest indices\n",
    "    dist_mat = pairDist( _new_data, _trainData )    \n",
    "    #dist_mat = tf.convert_to_tensor(dist_mat)\n",
    "    nearest_k, nearest_k_idx = nearestIndices(dist_mat, _k)\n",
    "    predict_res = tf.reduce_mean(tf.gather(_trainTarget, nearest_k_idx), 1)\n",
    "    #print(\"predict\", predict_res.eval())\n",
    "    return predict_res\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "#pairDist(testData) \n",
    "#pred_result = knn(testData, testTarget, _k = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plotResult(_trainData, _trainTarget):\n",
    "    X = np.linspace(0.0, 11.0, num = 100)[:, np.newaxis]\n",
    "    xTensor = tf.stack(X)\n",
    "    \n",
    "    num_neighbour_list = [1, 3, 5, 50]\n",
    "    for j in num_neighbour_list:\n",
    "        print(\"plot result\")\n",
    "        dist_mat = pairDist( X, _trainData ) \n",
    "        nearest_k, nearest_k_idx = nearestIndices(dist_mat, j)\n",
    "        predict_res = tf.reduce_mean(tf.gather(_trainTarget, nearest_k_idx), 1)\n",
    "\n",
    "        plt.figure()#(j+100)\n",
    "        plt.scatter(sessMain.run(_trainData), sessMain.run(_trainTarget))\n",
    "        plt.title(\"K = \" + str(j))\n",
    "        plt.plot(sessMain.run(xTensor), sessMain.run(predict_res))\n",
    "        \n",
    "        fileName = str(\"KNN\") + str(j) + str(\"trainingGraph.png\")\n",
    "        plt.savefig(fileName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testKValuesKNN(trainData, trainTarget, testData, testTarget):\n",
    "    num_neighbour_list = [1, 3, 5, 50]\n",
    "    loss_list = []\n",
    "\n",
    "    for j in num_neighbour_list:\n",
    "        print(\"j = \", j)\n",
    "        y_hat = knn(trainData, trainTarget, testData,  j)\n",
    "        #_y_hat = tf.transpose(_y_hat)\n",
    "        #mse_mat = euclideanDistance(_y_hat, _y) \n",
    "      \n",
    "        mse_mat = tf.square(tf.subtract(y_hat, testTarget))\n",
    "        loss = tf.reduce_mean(mse_mat)/2.0\n",
    "        print(\"neighbout = \" ,j)\n",
    "        loss_list.append(loss.eval())\n",
    "    return loss_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1():\n",
    "    np.random.seed(521)\n",
    "    Data = np.linspace(1.0 , 10.0 , num =100) [:, np. newaxis]\n",
    "    Target = np.sin( Data ) + 0.1 * np.power( Data , 2) \\\n",
    "         + 0.5 * np.random.randn(100 , 1)\n",
    "    randIdx = np.arange(100)\n",
    "    np.random.shuffle(randIdx)\n",
    "    trainData, trainTarget  = Data[randIdx[:80]], Target[randIdx[:80]]\n",
    "    validData, validTarget = Data[randIdx[80:90]], Target[randIdx[80:90]]\n",
    "    testData, testTarget = Data[randIdx[90:100]], Target[randIdx[90:100]]\n",
    "\n",
    "    # convert numpy array to tensors\n",
    "    trainData = tf.stack(trainData)\n",
    "    trainTarget = tf.stack(trainTarget)\n",
    "    testData = tf.stack(testData)\n",
    "    testTarget = tf.stack(testTarget)\n",
    "    validData = tf.stack(validData)\n",
    "    validtarget = tf.stack(validTarget)\n",
    "    \n",
    "    plotResult(trainData, trainTarget)\n",
    "    \n",
    "    loss_test = testKValuesKNN(trainData, trainTarget, testData, testTarget)\n",
    "    print(\"loss_test\", loss_test)\n",
    "    \n",
    "    loss_train = testKValuesKNN(trainData, trainTarget, trainData, trainTarget)\n",
    "    print(\"loss_train\" , loss_train)\n",
    "    \n",
    "    loss_valid = testKValuesKNN(trainData, trainTarget, validData, validTarget)\n",
    "    print(\"loss_valid\", loss_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss on Q1 KNN\n",
    "\n",
    "|k | 1 | 3 | 5| 50|\n",
    "|------|------|-----|-----|\n",
    "|test | 0.12799977712101845 | 0.14242504248546536 | 0.18633105926605592 | 0.70693467047889302 |\n",
    "|train | 0.0 | 0.10825207710580038 | 0.12183845521874122 | 1.2477892734500411 |\n",
    "|valid | 0.28807977607463453 | 0.30897640431136369 | 0.31043863052707066 | 1.2230445257949047 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_segmentation(data_path, target_path, task):\n",
    "    # task = 0 >> select the name ID targets for face recognition task\n",
    "    # task = 1 >> select the gender ID targets for gender recognition task data = np.load(data_path)/255\n",
    "    data = np.load(data_path)/255\n",
    "    data = np.reshape(data, [-1, 32*32])\n",
    "    target = np.load(target_path)\n",
    "    np.random.seed(45689)\n",
    "    rnd_idx = np.arange(np.shape(data)[0])\n",
    "    np.random.shuffle(rnd_idx)\n",
    "    trBatch = int(0.8*len(rnd_idx))\n",
    "    validBatch = int(0.1*len(rnd_idx))\n",
    "    trainData, validData, testData = data[rnd_idx[1:trBatch],:], \\\n",
    "                                   data[rnd_idx[trBatch+1:trBatch + validBatch],:],\\\n",
    "                                   data[rnd_idx[trBatch + validBatch+1:-1],:]\n",
    "    trainTarget, validTarget, testTarget = target[rnd_idx[1:trBatch], task], \\\n",
    "                              target[rnd_idx[trBatch+1:trBatch + validBatch], task],\\\n",
    "                              target[rnd_idx[trBatch + validBatch + 1:-1], task]\n",
    "    print(\"train data dim\", trainData.shape, \"valid data dim\", validData.shape,\n",
    "             \"test data dim\", testData.shape, \"trainTarget shape\", trainTarget.shape,\n",
    "             \"validTarget SHAPE\", validTarget.shape, \"testTarget shape\", testTarget.shape)\n",
    "    return trainData, validData, testData, trainTarget, validTarget, testTarget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knnVote(_trainData, _trainTarget, _new_data, _k):\n",
    "    '''\n",
    "    KNN using majority vote\n",
    "    '''\n",
    "    #nearest indices\n",
    "    dist_mat = pairDist( _new_data, _trainData ) \n",
    "    #print(\"in knn vote\", dist_mat)\n",
    "    \n",
    "    nearest_k, nearest_k_idx = nearestIndices(dist_mat, _k)\n",
    "    neighbours = tf.gather(_trainTarget, nearest_k_idx)\n",
    "    #print(\"in KNN vote neibours index before\", neighbours.eval())\n",
    "    \n",
    "    s1 = neighbours.shape[0]\n",
    "    n_unstack = tf.unstack(neighbours, axis = 0)\n",
    "    #print(\"n_unstack\", n_unstack)\n",
    "    #print(\"in Knn Vote neighbours after reshape\", neighbours.eval())\n",
    "\n",
    "    nearest_k_y, idx, votes = [], [], []\n",
    "    predict_res = []\n",
    "    for i in n_unstack:\n",
    "        y, i, v = tf.unique_with_counts(i) \n",
    "        nearest_k_y.append(y)\n",
    "        idx.append(i)\n",
    "        votes.append(v)\n",
    "        predict_res.append(y[tf.argmax(v)])\n",
    "        foo = tf.argmax(v)\n",
    "        #print(\"in KNN vote predict res argmax\", foo.eval() )\n",
    "        \n",
    "    predict_res = tf.convert_to_tensor(predict_res)\n",
    "    #print(\"in KNN vote predict\", predict_res.eval())\n",
    "\n",
    "    return predict_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testQ2KNN(trainData, trainTarget, testData, testTarget):\n",
    "    num_neighbour_list = [1, 5, 10, 25, 50, 100, 200]\n",
    "    loss_list = []\n",
    "    for j in num_neighbour_list:\n",
    "        print(\"knn, k = \", j)\n",
    "        y_hat = knnVote(trainData, trainTarget, testData,  j)\n",
    "        #testTarget = tf.cast(testTarget, tf.int64)\n",
    "        #print(\"testTarget shape\", testTarget.eval())\n",
    "        \n",
    "        y_hat = tf.cast(y_hat, tf.float16)\n",
    "        testTarget = tf.cast(testTarget, tf.float16)\n",
    "        # all the indices where y = target, bool\n",
    "        loss = tf.not_equal(y_hat, testTarget )\n",
    "        #cast bool to int\n",
    "        as_ints = tf.cast(loss, tf.int32)\n",
    "        error = tf.reduce_sum(as_ints)\n",
    "        #print(\"in testQ2KNN new error\", error.eval())\n",
    "        #print(\"neighbour = \" ,j)\n",
    "        \n",
    "        loss_list.append(error.eval())\n",
    "    return loss_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q2Task(t):\n",
    "    data_path = '/Users/vikuo/Documents/GitHub/ece521/assi/A1/data/data.npy'\n",
    "    target_path = '/Users/vikuo/Documents/GitHub/ece521/assi/A1/data/target.npy'\n",
    "    trainData, validData, testData, trainTarget, validTarget, testTarget = data_segmentation(data_path, target_path, t)\n",
    "    print(\"start q2 task \", t)\n",
    " \n",
    "    \n",
    "    \n",
    "    # convert numpy array to tensors\n",
    "    trainData = tf.stack(trainData)\n",
    "    #print(\"in q2() trainData shape\", trainData.eval())\n",
    "    trainTarget = tf.stack(trainTarget)\n",
    "    testData = tf.stack(testData)\n",
    "    testTarget = tf.stack(testTarget)\n",
    "    validData = tf.stack(validData)\n",
    "    validtarget = tf.stack(validTarget)\n",
    "    \n",
    "    loss_train = testQ2KNN(trainData, trainTarget, trainData, trainTarget) \n",
    "    print(\"loss train\", loss_train)\n",
    "    loss_test = testQ2KNN(trainData, trainTarget, testData, testTarget)\n",
    "    print(\"loss test\", loss_test) \n",
    "    loss_valid = testQ2KNN(trainData, trainTarget, validData, validTarget)\n",
    "    print(\"loss valid\", loss_valid)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data dim (747, 1024) valid data dim (92, 1024) test data dim (93, 1024) trainTarget shape (747,) validTarget SHAPE (92,) testTarget shape (93,)\n",
      "start q2 task  0\n",
      "knn, k =  1\n",
      "our k value 1\n",
      "knn, k =  5\n",
      "our k value 5\n",
      "knn, k =  10\n",
      "our k value 10\n",
      "knn, k =  25\n",
      "our k value 25\n",
      "knn, k =  50\n",
      "our k value 50\n",
      "knn, k =  100\n",
      "our k value 100\n",
      "knn, k =  200\n",
      "our k value 200\n",
      "loss train [0, 148, 206, 253, 308, 358, 428]\n",
      "knn, k =  1\n",
      "our k value 1\n",
      "knn, k =  5\n",
      "our k value 5\n",
      "knn, k =  10\n",
      "our k value 10\n",
      "knn, k =  25\n",
      "our k value 25\n",
      "knn, k =  50\n",
      "our k value 50\n",
      "knn, k =  100\n",
      "our k value 100\n",
      "knn, k =  200\n",
      "our k value 200\n",
      "loss test [27, 29, 31, 32, 39, 47, 56]\n",
      "knn, k =  1\n",
      "our k value 1\n",
      "knn, k =  5\n",
      "our k value 5\n",
      "knn, k =  10\n",
      "our k value 10\n",
      "knn, k =  25\n",
      "our k value 25\n",
      "knn, k =  50\n",
      "our k value 50\n",
      "knn, k =  100\n",
      "our k value 100\n",
      "knn, k =  200\n",
      "our k value 200\n",
      "loss valid [31, 36, 39, 37, 39, 48, 63]\n",
      "train data dim (747, 1024) valid data dim (92, 1024) test data dim (93, 1024) trainTarget shape (747,) validTarget SHAPE (92,) testTarget shape (93,)\n",
      "start q2 task  1\n",
      "knn, k =  1\n",
      "our k value 1\n",
      "knn, k =  5\n",
      "our k value 5\n",
      "knn, k =  10\n",
      "our k value 10\n",
      "knn, k =  25\n",
      "our k value 25\n",
      "knn, k =  50\n",
      "our k value 50\n",
      "knn, k =  100\n",
      "our k value 100\n",
      "knn, k =  200\n",
      "our k value 200\n",
      "loss train [0, 70, 73, 125, 132, 163, 205]\n",
      "knn, k =  1\n",
      "our k value 1\n",
      "knn, k =  5\n",
      "our k value 5\n",
      "knn, k =  10\n",
      "our k value 10\n",
      "knn, k =  25\n",
      "our k value 25\n",
      "knn, k =  50\n",
      "our k value 50\n",
      "knn, k =  100\n",
      "our k value 100\n",
      "knn, k =  200\n",
      "our k value 200\n",
      "loss test [7, 9, 10, 11, 13, 13, 21]\n",
      "knn, k =  1\n",
      "our k value 1\n",
      "knn, k =  5\n",
      "our k value 5\n",
      "knn, k =  10\n",
      "our k value 10\n",
      "knn, k =  25\n",
      "our k value 25\n",
      "knn, k =  50\n",
      "our k value 50\n",
      "knn, k =  100\n",
      "our k value 100\n",
      "knn, k =  200\n",
      "our k value 200\n",
      "loss valid [8, 8, 10, 9, 10, 13, 20]\n"
     ]
    }
   ],
   "source": [
    "from scipy import spatial as sp\n",
    "from sklearn import metrics as skm\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    sessMain = tf.InteractiveSession()\n",
    "    sessMain.run(init)\n",
    "    #q1()\n",
    "    q2Task(0)\n",
    "    q2Task(1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss on Q2 task 0 KNN\n",
    "\n",
    "|k | 1 | 5 | 10 | 25| 50 | 100 | 200 | \n",
    "|------|------|-----|-----|-----|-----|-----|\n",
    "|train | 0.0 | 0.85352 | 1.2578 | 1.4775 | 1.8555 | 2.1035| 2.584 |\n",
    "|test | 0.9248 | 0.78516 | 0.88184 | 1.043 | 1.376 |1.9893| 2.6875|\n",
    "|valid | 1.1631 | 1.3154 | 1.5439 | 1.5273 | 1.4131 |1.9678| 2.7832|\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "|k | 1 | 5 | 10 | 25| 50 | 100 | 200 | \n",
    "|------|------|-----|-----|-----|-----|-----|\n",
    "|train | 0.0 | 0.046844 | 0.048859 | 0.083679 | 0.088379 | 0.10913 | 0.13721 |\n",
    "|test |0.037628 | 0.048401 | 0.053772 | 0.059143 | 0.069885 | 0.069885 | 0.11292 |\n",
    "|valid | 0.043488 | 0.043488 | 0.054352 | 0.04892 | 0.054352 | 0.070679 | 0.1087 |\n",
    "\n",
    "\n",
    "loss train [0.0, 0.046844, 0.048859, 0.083679, 0.088379, 0.10913, 0.13721]\n",
    "loss test [0.037628, 0.048401, 0.053772, 0.059143, 0.069885, 0.069885, 0.11292]\n",
    "\n",
    "\n",
    "\n",
    "## Loss on Q2 task 0 KNN\n",
    "\n",
    "k | 1 | 5 | 10 | 25 | 50 | 100 | 200 \n",
    "--- | --- | --- | --- | --- | --- | --- | ---\n",
    "train | 0.0 | 0.85352 | 1.2578 | 1.4775 | 1.8555 | 2.1035 | 2.584 \n",
    "test | 0.9248 | 0.78516 | 0.88184 | 1.043 | 1.376 | 1.9893 | 2.6875\n",
    "valid | 1.1631 | 1.3154 | 1.5439 | 1.5273 | 1.4131 | 1.9678| 2.7832\n",
    "\n",
    "## Loss on Q2 task 1 KNN\n",
    "k | 1 | 5 | 10 | 25 | 50 | 100 | 200 \n",
    "--- | --- | --- | --- | --- | --- | --- | ---\n",
    "train | 0.0 | 0.046844 | 0.048859 | 0.083679 | 0.088379 | 0.10913 | 0.13721 |\n",
    "test | 0.037628 | 0.048401 | 0.053772 | 0.059143 | 0.069885 | 0.069885 | 0.11292 |\n",
    "valid | 0.043488 | 0.043488 | 0.054352 | 0.04892 | 0.054352 | 0.070679 | 0.1087 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss representation in indicator function instead of squared difference\n",
    "## Loss on Q2 task 0 KNN\n",
    "\n",
    "\n",
    "note: total dim | train 747 | valid 92 | test 94 |\n",
    "\n",
    "\n",
    "k | 1 | 5 | 10 | 25 | 50 | 100 | 200 \n",
    "--- | --- | --- | --- | --- | --- | --- | ---\n",
    "train | 0 | 148 | 206 | 253 | 308 | 358 | 428\n",
    "test | 27 | 29 | 31 | 32 | 39 | 47 | 56\n",
    "valid | 31 | 36 | 39 | 37| 39 | 48 | 63\n",
    "\n",
    "## Loss on Q2 task 1 KNN\n",
    "k | 1 | 5 | 10 | 25 | 50 | 100 | 200 \n",
    "--- | --- | --- | --- | --- | --- | --- | ---\n",
    "train |  0 | 70| 73 | 125 | 132 | 163 | 205\n",
    "test |  7 | 9 | 10 | 11 | 13 | 13 | 21 \n",
    "valid | 8 | 8 | 10 | 9 | 10 | 13 | 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
