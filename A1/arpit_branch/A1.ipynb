{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P1 - Eucidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_dist(x, z):\n",
    "    \n",
    "    #||x - z||^2 = x.T*x - 2*x*z.T + z.T*z\n",
    "    \n",
    "    #can also be tried using linalg.norm function\n",
    "    \n",
    "    x2 = tf.matmul(x ,tf.transpose(x))\n",
    "    z2 = tf.matmul(z ,tf.transpose(z))\n",
    "    \n",
    "    x2_sum = tf.reduce_sum(x2, axis = 1)\n",
    "    z2_sum = tf.reduce_sum(z2, axis = 1)\n",
    "    \n",
    "    xt = tf.transpose(x2_sum)\n",
    "    zt = tf.transpose(z2_sum)\n",
    "    \n",
    "    xz = tf.matmul(x, tf.transpose(z))\n",
    "    minus_xz = tf.scalar_mul(-2, xz)\n",
    "    \n",
    "    xt = tf.expand_dims(xt, axis = 1)\n",
    "    zt = tf.expand_dims(zt, axis = 1)\n",
    "    zt = tf.transpose(zt)\n",
    "    \n",
    "    xz2 = xt + zt + minus_xz\n",
    "    \n",
    "    return xz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[48 62 76]\n",
      " [60 70 80]\n",
      " [72 78 84]\n",
      " [84 86 88]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "a = tf.constant([[1, 1], [2, 2], [3, 3], [4, 4]])\n",
    "b = tf.constant([[2, 2], [3, 3], [4, 4]])\n",
    "\n",
    "c = euclidean_dist(a, b)\n",
    "print(sess.run(c))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_dist(data1, data2):\n",
    "    data1 = tf.convert_to_tensor(data1)\n",
    "    data2 = tf.convert_to_tensor(data2)\n",
    "    \n",
    "    dist = euclidean_dist(data1, data2)\n",
    "    return dist\n",
    "\n",
    "def knn_predict(_trainData, _trainTarget, _X, _k):\n",
    "    dist = pairwise_dist(_trainData, _X)\n",
    "    near_k, near_id = tf.nn.top_k(dist, _k)\n",
    "    respon = tf.gather(_trainData, near_id)\n",
    "    respon = tf.reduce_mean(respon, axis = 1)\n",
    "    \n",
    "    return respon\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40 54 68]\n",
      " [44 54 64]\n",
      " [48 54 60]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "a = tf.constant([[1, 1], [2, 2], [3, 3]])\n",
    "b = tf.constant([[2, 2], [3, 3], [4, 4]])\n",
    "\n",
    "c = pairwise_dist(a, b)\n",
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(trainData, trainTarget, testData, testTarget):\n",
    "    \n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(_trainData, _trainTarget):\n",
    "    X = np.linspace(0.0, 11.0, num = 1000) [:, np.newaxis]\n",
    "    X = tf.convert_to_tensor(X)\n",
    "    \n",
    "    k_list = [1, 3, 5, 50]\n",
    "    \n",
    "    for k in k_list:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(521)\n",
    "Data = np.linspace(1.0 , 10.0 , num =100) [:, np. newaxis]\n",
    "Target = np.sin( Data ) + 0.1 * np.power( Data , 2) \\\n",
    "+ 0.5 * np.random.randn(100 , 1)\n",
    "randIdx = np.arange(100)\n",
    "np.random.shuffle(randIdx)\n",
    "trainData, trainTarget = Data[randIdx[:80]], Target[randIdx[:80]]\n",
    "validData, validTarget = Data[randIdx[80:90]], Target[randIdx[80:90]]\n",
    "testData, testTarget = Data[randIdx[90:100]], Target[randIdx[90:100]]\n",
    "\n",
    "trainData = tf.convert_to_tensor(trainData)\n",
    "trainTarget = tf.convert_to_tensor(trainTarget)\n",
    "testData = tf.convert_to_tensor(testData)\n",
    "testTarget = tf.convert_to_tensor(testTarget)\n",
    "validData = tf.convert_to_tensor(validData)\n",
    "validtarget = tf.convert_to_tensor(validTarget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P3 (Using Violet's Code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclideanDistance(x, z):\n",
    "    '''\n",
    "    We vectorized the operation with matrix operations\n",
    "    the ||x - z ||^2 is = Sum(x - z)^2 = Sum from 1 to D\n",
    "    of (x^2 - 2xz + z^2)\n",
    "    \n",
    "    x^2 = x^T times x\n",
    "    z^2 = z^T times z\n",
    "    we can find the sum of each row by using the reduce sum function\n",
    "    \n",
    "    sum of -2xz \n",
    "    we can use matrix multiplication, x times z^T to obtain xz,\n",
    "    then multiply by -2\n",
    "    '''\n",
    "    n1 = x.shape[0]\n",
    "    n2 = z.shape[0]    \n",
    "    \n",
    "    x_squared = tf.square(x)\n",
    "    z_squared = tf.square(z) #tf.matmul(z ,tf.transpose(z))\n",
    "    #print(\"x_squared.eval()\")\n",
    "    #print(x_squared.eval())\n",
    "    x_2_sum = tf.reduce_sum(x_squared, 1)\n",
    "    z_2_sum = tf.reduce_sum(z_squared, 1)\n",
    "    \n",
    "    x_2_sum = tf.transpose(x_2_sum)\n",
    "    z_2_sum = tf.transpose(z_2_sum)\n",
    "    #x_2_sum = tf.reshape(x_2_sum, [-1, 1])\n",
    "    #z_2_sum = tf.reshape(z_2_sum, [-1, 1])\n",
    "    #print(\"x_2_sum.eval()\")\n",
    "    #print(x_2_sum.eval())\n",
    "    \n",
    "    xz = tf.matmul(x, tf.transpose(z))\n",
    "    #print(xz.eval())\n",
    "    minus_2xz = tf.scalar_mul(-2, xz)\n",
    "    #print(minus_2xz.eval())\n",
    " \n",
    "    x_2_tile =tf.tile(tf.expand_dims(x_2_sum, 1), [1, n2])\n",
    "    z_2_tile = tf.tile(tf.expand_dims(z_2_sum ,1), [1, n1])\n",
    "    z_2_tile_T = tf.transpose(z_2_tile)\n",
    "    #print(x_2_tile.eval())\n",
    "    #print(z_2_tile_T.eval())\n",
    "    \n",
    "    result = x_2_tile + minus_2xz +z_2_tile_T\n",
    "    \n",
    "    return result\n",
    "\n",
    "\"\"\"VERIFIED\"\"\"\n",
    "\n",
    "def testi():\n",
    "    A = tf.constant([[1, 1], [2,2], [3, 3], [4,4]])\n",
    "    B = tf.constant([[1, 1], [2, 2],[3,3]])\n",
    "    res_mine = euclideanDistance(A, B)\n",
    "    \n",
    "    print(\"----my func----\")\n",
    "    print(res_mine.eval())\n",
    "    print(\"---diff square---\")\n",
    "    res_lib = PairwiseDistances(A, B)\n",
    "    print(res_lib.eval())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearestIndices(_dist_mat, _k):\n",
    "\n",
    "    nearest_k_data, nearest_k_indices = tf.nn.top_k(tf.negative(_dist_mat), _k)\n",
    "    return nearest_k_data, nearest_k_indices\n",
    "\n",
    "\n",
    "#unit testing\n",
    "#dist_mat = tf.constant([ 4, 9, 16, 25 ], tf.int32)\n",
    "#topk = nearestIndices(dist_mat, 2)\n",
    "#responsibility(topk, 2, 4)\n",
    "\n",
    "def pairDist(_data, _data1):\n",
    "    data_t = tf.convert_to_tensor(_data)\n",
    "    data1_t = tf.convert_to_tensor(_data1)\n",
    "    dist = euclideanDistance(data_t, data1_t)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_segmentation(data_path, target_path, task):\n",
    "    # task = 0 >> select the name ID targets for face recognition task\n",
    "    # task = 1 >> select the gender ID targets for gender recognition task data = np.load(data_path)/255\n",
    "    data = np.load(data_path)/255\n",
    "    data = np.reshape(data, [-1, 32*32])\n",
    "    target = np.load(target_path)\n",
    "    np.random.seed(45689)\n",
    "    rnd_idx = np.arange(np.shape(data)[0])\n",
    "    np.random.shuffle(rnd_idx)\n",
    "    trBatch = int(0.8*len(rnd_idx))\n",
    "    validBatch = int(0.1*len(rnd_idx))\n",
    "    trainData, validData, testData = data[rnd_idx[1:trBatch],:], \\\n",
    "                                   data[rnd_idx[trBatch+1:trBatch + validBatch],:],\\\n",
    "                                   data[rnd_idx[trBatch + validBatch+1:-1],:]\n",
    "    trainTarget, validTarget, testTarget = target[rnd_idx[1:trBatch], task], \\\n",
    "                              target[rnd_idx[trBatch+1:trBatch + validBatch], task],\\\n",
    "                              target[rnd_idx[trBatch + validBatch + 1:-1], task]\n",
    "    #print(\"train data dim\", trainData.shape, \"valid data dim\", validData.shape,\n",
    "             #\"test data dim\", testData.shape, \"trainTarget shape\", trainTarget.shape,\n",
    "             #\"validTarget SHAPE\", validTarget.shape, \"testTarget shape\", testTarget.shape)\n",
    "    return trainData, validData, testData, trainTarget, validTarget, testTarget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knnVote(_trainData, _trainTarget, _new_data, _new_target, _k):\n",
    "    '''\n",
    "    KNN using majority vote\n",
    "    '''\n",
    "    #nearest indices\n",
    "    dist_mat = pairDist( _new_data, _trainData ) \n",
    "    \n",
    "    nearest_k, nearest_k_idx = nearestIndices(dist_mat, _k)\n",
    "    neighbours = tf.gather(_trainTarget, nearest_k_idx)\n",
    "    \n",
    "    s1 = neighbours.shape[0]\n",
    "    n_unstack = tf.unstack(neighbours, axis = 0)\n",
    "\n",
    "    nearest_k_y, idx, votes = [], [], []\n",
    "    predict_res = []\n",
    "    \n",
    "    check = False\n",
    "    curr_id = 0\n",
    "    \n",
    "    for i in n_unstack:\n",
    "        y, i, v = tf.unique_with_counts(i) \n",
    "        nearest_k_y.append(y)\n",
    "        idx.append(i)\n",
    "        votes.append(v)\n",
    "        predict_res.append(y[tf.argmax(v)])\n",
    "        votes.append(tf.argmax(v)) #record the indices chosen\n",
    "        \n",
    "        if k == 10 and check == False:\n",
    "            display_k10(_trainData, _trainTarget, _new_data, _new_target, nearest_k_idx, curr_id, y, v)\n",
    "            curr_id += 1\n",
    "            check = True\n",
    "        \n",
    "    predict_res = tf.convert_to_tensor(predict_res)\n",
    "\n",
    "    return predict_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testQ2KNN(trainData, trainTarget, testData, testTarget):\n",
    "    num_neighbour_list = [1, 5, 10, 25, 50, 100, 200]\n",
    "    loss_list = []\n",
    "    for j in num_neighbour_list:\n",
    "        #print(\"running knn, k = \", j)\n",
    "        y_hat = knnVote(trainData, trainTarget, testData, testTarget, j)\n",
    "        y_hat = tf.cast(y_hat, tf.float16)\n",
    "        testTarget = tf.cast(testTarget, tf.float16)\n",
    "        # all the indices where y = target, bool\n",
    "        loss = tf.not_equal(y_hat, testTarget )\n",
    "        #cast bool to int\n",
    "        as_ints = tf.cast(loss, tf.int32)\n",
    "        error = tf.reduce_sum(as_ints)\n",
    "        loss_list.append(error.eval())\n",
    "    return loss_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_k10(_trainData, _trainTarget, _newData, _newTarget, k_id, curr_id, y, v):\n",
    "    \n",
    "    test_data = tf.gather(_newData, curr_id)\n",
    "    neighbour = tf.gather(_trainData, k_id)\n",
    "    curr_target = tf.cast(_newTarget[curr_id], tf.uint8)\n",
    "    if tf.not_equal(y[tf.argmax(v)], curr_target):\n",
    "        plot_k10(test_data, neighbour)\n",
    "        plt.imshow(test_data)\n",
    "        plt.Title(\"Failure Case\")\n",
    "        plt.show()\n",
    "        \n",
    "        for i in range(10):\n",
    "            neighbor_img = tf.reshape(neighbor[i, :], [32, 32])\n",
    "            plt.imshow(neighbor_img)\n",
    "            title = i + \"st nearest neighbor\"\n",
    "            plt.Title(title)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q2Task(t):\n",
    "    data_path = 'data.npy'\n",
    "    target_path = 'target.npy'\n",
    "    trainData, validData, testData, trainTarget, validTarget, testTarget = data_segmentation(data_path, target_path, t)\n",
    "       \n",
    "    # convert numpy array to tensors\n",
    "    trainData = tf.stack(trainData)\n",
    "    trainTarget = tf.stack(trainTarget)\n",
    "    testData = tf.stack(testData)\n",
    "    testTarget = tf.stack(testTarget)\n",
    "    validData = tf.stack(validData)\n",
    "    validtarget = tf.stack(validTarget)\n",
    "    \n",
    "    print(\"********** BEGIN Q2 task \", t, \" ***********\")\n",
    "    loss_train = testQ2KNN(trainData, trainTarget, trainData, trainTarget) \n",
    "    print(\"q2 task\", t, \"loss train\", loss_train)\n",
    "    loss_test = testQ2KNN(trainData, trainTarget, testData, testTarget)\n",
    "    print(\"q2 task\", t,  \"loss test\", loss_test) \n",
    "    loss_valid = testQ2KNN(trainData, trainTarget, validData, validTarget)\n",
    "    print(\"q2 task\", t , \"loss valid\", loss_valid)\n",
    "    print(\"********** END Q2 task \", t, \" ***********\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** BEGIN Q2 task  0  ***********\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Failed to convert object of type <class 'list'> to Tensor. Contents: [1, Dimension(747)]. Consider casting elements to a supported type.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\arpit\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[1;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 460\u001b[1;33m       \u001b[0mstr_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    461\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arpit\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 460\u001b[1;33m       \u001b[0mstr_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    461\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arpit\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\util\\compat.py\u001b[0m in \u001b[0;36mas_bytes\u001b[1;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[0;32m     64\u001b[0m     raise TypeError('Expected binary or unicode string, got %r' %\n\u001b[1;32m---> 65\u001b[1;33m                     (bytes_or_text,))\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Expected binary or unicode string, got 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-870048e93300>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0msessMain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m#q1()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mq2Task\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mq2Task\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-d87821af29b3>\u001b[0m in \u001b[0;36mq2Task\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"********** BEGIN Q2 task \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\" ***********\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mloss_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtestQ2KNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainTarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainTarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"q2 task\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"loss train\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mloss_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtestQ2KNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainTarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestTarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-4c52b51c31c2>\u001b[0m in \u001b[0;36mtestQ2KNN\u001b[1;34m(trainData, trainTarget, testData, testTarget)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnum_neighbour_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;31m#print(\"running knn, k = \", j)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknnVote\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainTarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestTarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mtestTarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestTarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-dbc9776df7ac>\u001b[0m in \u001b[0;36mknnVote\u001b[1;34m(_trainData, _trainTarget, _new_data, _new_target, _k)\u001b[0m\n\u001b[0;32m      4\u001b[0m     '''\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m#nearest indices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mdist_mat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpairDist\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0m_new_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_trainData\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mnearest_k\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnearest_k_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnearestIndices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdist_mat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-2146d50983a8>\u001b[0m in \u001b[0;36mpairDist\u001b[1;34m(_data, _data1)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mdata_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mdata1_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_data1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mdist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meuclideanDistance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata1_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-b1e607f17f10>\u001b[0m in \u001b[0;36meuclideanDistance\u001b[1;34m(x, z)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;31m#print(minus_2xz.eval())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0mx_2_tile\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_2_sum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m     \u001b[0mz_2_tile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_2_sum\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mz_2_tile_T\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_2_tile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arpit\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mtile\u001b[1;34m(input, multiples, name)\u001b[0m\n\u001b[0;32m   3845\u001b[0m   \"\"\"\n\u001b[0;32m   3846\u001b[0m   result = _op_def_lib.apply_op(\"Tile\", input=input, multiples=multiples,\n\u001b[1;32m-> 3847\u001b[1;33m                                 name=name)\n\u001b[0m\u001b[0;32m   3848\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arpit\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    491\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m               raise TypeError(\n",
      "\u001b[1;32mc:\\users\\arpit\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    488\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 490\u001b[1;33m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[0;32m    491\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arpit\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype)\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m           \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arpit\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    119\u001b[0m                                          as_ref=False):\n\u001b[0;32m    120\u001b[0m   \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arpit\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[0mtensor_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[1;32m--> 102\u001b[1;33m       tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[0;32m    103\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[1;32mc:\\users\\arpit\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[1;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    462\u001b[0m       raise TypeError(\"Failed to convert object of type %s to Tensor. \"\n\u001b[0;32m    463\u001b[0m                       \u001b[1;34m\"Contents: %s. Consider casting elements to a \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m                       \"supported type.\" % (type(values), values))\n\u001b[0m\u001b[0;32m    465\u001b[0m     \u001b[0mtensor_proto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor_proto\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Failed to convert object of type <class 'list'> to Tensor. Contents: [1, Dimension(747)]. Consider casting elements to a supported type."
     ]
    }
   ],
   "source": [
    "from scipy import spatial as sp\n",
    "from sklearn import metrics as skm\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    sessMain = tf.InteractiveSession()\n",
    "    sessMain.run(init)\n",
    "    #q1()\n",
    "    q2Task(0)\n",
    "    q2Task(1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
