{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "class BatchSampler(object):\n",
    "    '''\n",
    "    A (very) simple wrapper to randomly sample batches without replacement.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, data, targets, batch_size):\n",
    "        self.num_points = data.shape[0]\n",
    "        self.features = data.shape[1]\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.batch_size = batch_size\n",
    "        self.indices = np.arange(self.num_points)\n",
    "\n",
    "    def random_batch_indices(self, m=None):\n",
    "        if m is None:\n",
    "            indices = np.random.choice(self.indices, self.batch_size, replace=False)\n",
    "        else:\n",
    "            indices = np.random.choice(self.indices, m, replace=False)\n",
    "        return indices \n",
    "\n",
    "    def get_batch(self, m=None):\n",
    "        '''\n",
    "        Get a random batch without replacement from the dataset.\n",
    "        If m is given the batch will be of size m. \n",
    "        Otherwise will default to the class initialized value.\n",
    "        '''\n",
    "        indices = self.random_batch_indices(m)\n",
    "        X_batch = np.take(self.data, indices, 0)\n",
    "        y_batch = self.targets[indices]\n",
    "        return X_batch, y_batch  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotFig(_num, _dim, y , addInfo, title=\"default\", xLabel=\"xlabel\", yLabel=\"yLabel\", plotLabel =\"plotLabel\" ):\n",
    "    x = np.linspace(0, _dim, num=_dim)\n",
    "   \n",
    "    \n",
    "    y = np.array(y)\n",
    "    print(y.shape)\n",
    "    plt.figure(_num)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xLabel)\n",
    "    plt.ylabel(yLabel)\n",
    "    for i in range(y.shape[0]):\n",
    "        plt.plot(x, y[i], label = plotLabel + str(addInfo[i]))\n",
    "        \n",
    "    plt.legend()\n",
    "    plt.savefig( title + str(_num) + \".png\")\n",
    "    plt.close()\n",
    "    plt.clf()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data binary class Loaded\n",
      "-------------------------------\n",
      "(3500, 28, 28)\n",
      "(100, 28, 28)\n",
      "(145, 28, 28)\n",
      "****** START Q1.1 *****\n",
      "regTerm Tensor(\"Mul_1:0\", shape=(), dtype=float32)\n",
      "crossEntropyErrorCurr Tensor(\"Add:0\", shape=(), dtype=float32)\n",
      "learningrate =  0.005\n",
      "current err 0.728765\n",
      "epoch  0.0\n",
      "current err 0.533234\n",
      "epoch  1.0\n",
      "regTerm Tensor(\"Mul_1:0\", shape=(), dtype=float32)\n",
      "crossEntropyErrorCurr Tensor(\"Add:0\", shape=(), dtype=float32)\n",
      "learningrate =  0.001\n",
      "current err 0.782692\n",
      "epoch  0.0\n",
      "current err 0.555921\n",
      "epoch  1.0\n",
      "regTerm Tensor(\"Mul_1:0\", shape=(), dtype=float32)\n",
      "crossEntropyErrorCurr Tensor(\"Add:0\", shape=(), dtype=float32)\n",
      "learningrate =  0.0001\n",
      "current err 0.787484\n",
      "epoch  0.0\n",
      "current err 0.659586\n",
      "epoch  1.0\n",
      "train done\n",
      "(3, 5000)\n",
      "(3, 5000)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-14e7effdc24d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"****** START Q1.1 *****\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m     \u001b[0mrunLogisticGraphPart1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainTarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidTarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestTarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-14e7effdc24d>\u001b[0m in \u001b[0;36mrunLogisticGraphPart1\u001b[0;34m(trainData, trainTarget, validData, validTarget, testData, testTarget)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0mplotFig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumIter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainLossAll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearningRateArr\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Q2-1 logistic loss vs number of epoches\"\u001b[0m\u001b[0;34m,\u001b[0m            \u001b[0mplotLabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"learning rate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m     \u001b[0mplotFig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumIter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmseLossAll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearningRateArr\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Q2-1 MSE loss vs number of epoches\"\u001b[0m\u001b[0;34m,\u001b[0m            \u001b[0mplotLabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"learning rate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-f7e5d400d437>\u001b[0m in \u001b[0;36mplotFig\u001b[0;34m(_num, _dim, y, addInfo, title, xLabel, yLabel, plotLabel)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myLabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplotLabel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddInfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3259\u001b[0m                       mplDeprecation)\n\u001b[1;32m   3260\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3261\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3262\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3263\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1715\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1716\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1717\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1718\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36madd_line\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m   1777\u001b[0m             \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1779\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_line_limits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1780\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m             \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_line%d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_update_line_limits\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m   1799\u001b[0m         \u001b[0mFigures\u001b[0m \u001b[0mout\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mlimit\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdating\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataLim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1800\u001b[0m         \"\"\"\n\u001b[0;32m-> 1801\u001b[0;31m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1802\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1803\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mget_path\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    955\u001b[0m         \"\"\"\n\u001b[1;32m    956\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidy\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 957\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    958\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mrecache\u001b[0;34m(self, always)\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0malways\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m             \u001b[0myconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_yunits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_yorig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_unmasked_float_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myconv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36m_to_unmasked_float_array\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   2005\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2007\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \"\"\"\n\u001b[0;32m--> 531\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f76e2940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def loadBinData():\n",
    "# import binary NOTMIST data set\n",
    "    with np.load(\"notMNIST.npz\") as data :\n",
    "        Data, Target = data [\"images\"], data[\"labels\"]\n",
    "        posClass = 2\n",
    "        negClass = 9\n",
    "        dataIndx = (Target==posClass) + (Target==negClass)\n",
    "        Data = Data[dataIndx]/255.\n",
    "        Target = Target[dataIndx].reshape(-1, 1)\n",
    "        Target[Target==posClass] = 1\n",
    "        Target[Target==negClass] = 0\n",
    "        np.random.seed(521)\n",
    "        randIndx = np.arange(len(Data))\n",
    "        np.random.shuffle(randIndx)\n",
    "        Data, Target = Data[randIndx], Target[randIndx]\n",
    "        trainData, trainTarget = Data[:3500], Target[:3500]\n",
    "        validData, validTarget = Data[3500:3600], Target[3500:3600]\n",
    "        testData, testTarget = Data[3600:], Target[3600:]\n",
    "        \n",
    "    print(\"Data binary class Loaded\")\n",
    "    print(\"-------------------------------\")\n",
    "    return trainData, trainTarget,validData, validTarget,\\\n",
    "        testData, testTarget\n",
    "\n",
    "def linearMSE(y_hat, target):\n",
    "    '''\n",
    "    TODO: the MSE calculation\n",
    "    '''\n",
    "    #print(\"y_hat\",  y_hat)\n",
    "    \n",
    "    se_mat = tf.square(tf.subtract(y_hat, target))\n",
    "    #print(\"msemst\", mse_mat)\n",
    "    mse_mat = tf.reduce_mean(se_mat)\n",
    "    loss = tf.reduce_mean(mse_mat)\n",
    "    loss = tf.div(loss, tf.constant(2.0))\n",
    "\n",
    "    return loss    \n",
    "    \n",
    "\n",
    "def arrFlatten(arr):\n",
    "    \n",
    "    print(arr.shape)\n",
    "\n",
    "    dataDim1, dum1, dum2 = arr.shape\n",
    "    arr = np.reshape(arr, [ dataDim1 ,784 ])\n",
    "    return arr\n",
    "\n",
    "\n",
    "\n",
    "def logisticBuildGraph(_regLambda, _learningRate, gd):\n",
    "    '''\n",
    "    Input: _data is x in the equation, dim by 784 flattened tensor\n",
    "       _target is y in the equaion\n",
    "       _regLambda is the wegithed decay coeff\n",
    "       _learningRate is the epsilon\n",
    "    '''\n",
    "\n",
    "    #declare using a placeholder, feed in _data and _target to x ,y \n",
    "    #x_dim, dum1 =_data.get_shape().as_list()\n",
    "    X = tf.placeholder(tf.float32, shape=[None, 784], name='dataX')\n",
    "    # W initialize to a gaussian distr, honestly anything would work\n",
    "    W = tf.Variable(tf.truncated_normal(shape=[784, 1], stddev=0.1), name='weights')\n",
    "    W = tf.cast(W, dtype=tf.float32)\n",
    "    b = tf.Variable(0.0, name='biases')\n",
    "    y_target = tf.placeholder(tf.float32, shape=[None, 1], name='targetY')\n",
    "    \n",
    "    #compute the current y_hat\n",
    "    wtxb =  tf.matmul(X, W) + b\n",
    "    y_hat = tf.sigmoid(wtxb)\n",
    "    #compute the current loss\n",
    "    crossEntropyErrorCurr = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y_target, logits= y_hat))\n",
    "\n",
    "    #compute the decay/regularization term\n",
    "    regTerm = tf.multiply( 0.50, tf.multiply(_regLambda, tf.reduce_mean(tf.square(W))))\n",
    "    print(\"regTerm\", regTerm)\n",
    "    crossEntropyErrorCurr = tf.add(crossEntropyErrorCurr, regTerm)\n",
    "    print(\"crossEntropyErrorCurr\", crossEntropyErrorCurr)\n",
    "    \n",
    "    if gd == True:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate = _learningRate)\n",
    "    else:\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate = _learningRate)\n",
    "    \n",
    "    train = optimizer.minimize(loss=crossEntropyErrorCurr)\n",
    "\n",
    "    return W, b, crossEntropyErrorCurr, y_hat, X, y_target, train\n",
    "\n",
    "\n",
    "def runLogisticGraphPart1(trainData, trainTarget, validData, validTarget,testData, testTarget):\n",
    "    '''\n",
    "    Input: _data,\n",
    "           _target,\n",
    "           _numIters\n",
    "    Output:\n",
    "           required accuracy/epoch plots\n",
    "           \n",
    "    '''\n",
    "    \n",
    "    regLambda = 0.01\n",
    "    learningRateArr = [0.005, 0.001, 0.0001]\n",
    "    numIter = 5000\n",
    "    numEpoch =int(np.ceil(20000/7))\n",
    "    batchSize = 500\n",
    "    epochTrainSize = 3500 #for training data\n",
    "    trainLossAll = []\n",
    "    mseLossAll = []\n",
    "    \n",
    "    for learningRate in learningRateArr:\n",
    "        trainLossLR = []\n",
    "        mseLossLR = []\n",
    "        tf.reset_default_graph()\n",
    "        W, b, crossEntropyErrorCurr, y_hat, X, y_target, train = logisticBuildGraph(regLambda, learningRate, True)\n",
    "    \n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess = tf.InteractiveSession()\n",
    "        sess.run(init)\n",
    "        initialW = sess.run(W)  \n",
    "        initialb = sess.run(b)            \n",
    "        #training model and iter through batches\n",
    "        print(\"learningrate = \", learningRate)\n",
    "        \n",
    "        for i in range(numIter):\n",
    "            trainBatchSampler = BatchSampler(trainData, trainTarget, batchSize)\n",
    "            dataBatch, targetBatch = trainBatchSampler.get_batch()\n",
    "            #dataBatch = tf.stack(dataBatch)\n",
    "            #targetBatch = tf.stack(targetBatch)\n",
    "            currentW, currentb, errTrain, y_predict, trainModel = sess.run([W, b, crossEntropyErrorCurr, y_hat, train], feed_dict={X: dataBatch, y_target: targetBatch})\n",
    "            trainLossLR.append(errTrain)\n",
    "            mseLoss = linearMSE(y_predict, targetBatch)\n",
    "            mseLossLR.append(mseLoss)\n",
    "            \n",
    "            if i%3500 == 0:\n",
    "                print(\"current err\", errTrain)\n",
    "                print(\"epoch \", i/3500)\n",
    "        \n",
    "        trainLossAll.append(trainLossLR)\n",
    "        mseLossAll.append(mseLossLR)\n",
    "        \n",
    "    print(\"train done\")\n",
    "    plotFig(1, numIter, trainLossAll, learningRateArr,  title = \"Q2-1 logistic loss vs number of epoches\",\\\n",
    "            plotLabel=\"learning rate\")\n",
    "    \n",
    "    plotFig(1, numIter, mseLossAll, learningRateArr,  title = \"Q2-1 MSE loss vs number of epoches\",\\\n",
    "            plotLabel=\"learning rate\")\n",
    "\n",
    "\n",
    "    \n",
    "def runLogisticGraphPart2(trainData, trainTarget):\n",
    "    regLambda = 0.01\n",
    "    learningRate = 0.001\n",
    "    learningRateArr = [0.001]\n",
    "    numIter = 5000\n",
    "    numEpoch =int(np.ceil(20000/7))\n",
    "    batchSize = 500\n",
    "    epochTrainSize = 3500 #for training data\n",
    "    trainLossAll = []\n",
    "    \n",
    "    \n",
    "   \n",
    "    trainLossLR = []\n",
    "    tf.reset_default_graph()\n",
    "    W, b, crossEntropyErrorCurr, y_hat, X, y_target, train = logisticBuildGraph(regLambda, learningRate, False)\n",
    "    \n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.InteractiveSession()\n",
    "    sess.run(init)\n",
    "    initialW = sess.run(W)  \n",
    "    initialb = sess.run(b)            \n",
    "    #training model and iter through batches\n",
    "    print(\"learningrate = \", learningRate)\n",
    "        \n",
    "    for i in range(numIter):\n",
    "        trainBatchSampler = BatchSampler(trainData, trainTarget, batchSize)\n",
    "        dataBatch, targetBatch = trainBatchSampler.get_batch()\n",
    "        #dataBatch = tf.stack(dataBatch)\n",
    "        #targetBatch = tf.stack(targetBatch)\n",
    "        currentW, currentb, errTrain, y_predict, trainModel = sess.run([W, b, crossEntropyErrorCurr, y_hat, train], feed_dict={X: dataBatch, y_target: targetBatch})\n",
    "        trainLossLR.append(errTrain)\n",
    "        if i%3500 == 0:\n",
    "            print(\"current err\", errTrain)\n",
    "            print(\"epoch \", i/3500)\n",
    "        \n",
    "    trainLossAll.append(trainLossLR)\n",
    "    \n",
    "    print(\"train done\")\n",
    "    plotFig(1, numIter, trainLossAll, learningRateArr,  title = \"q2-2 logistic loss vs number of epoches\",\\\n",
    "            plotLabel=\"learning rate\")\n",
    "\n",
    "    \n",
    "     \n",
    "\n",
    "\n",
    "if __name__ == '__main__':  \n",
    "        \n",
    "\n",
    "    #trainTarget = arrFlatten(trainTarget)\n",
    "    trainData, trainTarget, validData, validTarget,testData, testTarget = loadBinData()\n",
    "    #data is (3500, 28, 28)\n",
    "    #the label [1] or [0] is stored in target\n",
    "    trainData = arrFlatten(trainData)\n",
    "    validData = arrFlatten(validData)\n",
    "    testData = arrFlatten(testData)\n",
    "    \n",
    "    print(\"****** START Q1.1 *****\")\n",
    "    runLogisticGraphPart1(trainData, trainTarget, validData, validTarget,testData, testTarget)\n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "       \n",
    "    print(\"****** START Q1.2 *****\")\n",
    "    runLogisticGraphPart2(trainData, trainTarget)\n",
    "    runLogisticGraphPart3(trainData, trainTarget, validData, validTarget,testData, testTarget )\n",
    "    '''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
