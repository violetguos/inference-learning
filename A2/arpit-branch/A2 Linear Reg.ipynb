{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use temporarily until tf.train bug is fixed \n",
    "#violet's mini batch code\n",
    "class BatchSampler(object):\n",
    "    '''\n",
    "    A (very) simple wrapper to randomly sample batches without replacement.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, data, targets, batch_size):\n",
    "        self.num_points = data.shape[0]\n",
    "        self.features = data.shape[1]\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.batch_size = batch_size\n",
    "        self.indices = np.arange(self.num_points)\n",
    "\n",
    "    def random_batch_indices(self, m=None):\n",
    "        if m is None:\n",
    "            indices = np.random.choice(self.indices, self.batch_size, replace=False)\n",
    "        else:\n",
    "            indices = np.random.choice(self.indices, m, replace=False)\n",
    "        return indices \n",
    "\n",
    "    def get_batch(self, m=None):\n",
    "        '''\n",
    "        Get a random batch without replacement from the dataset.\n",
    "        If m is given the batch will be of size m. \n",
    "        Otherwise will default to the class initialized value.\n",
    "        '''\n",
    "        indices = self.random_batch_indices(m)\n",
    "        X_batch = np.take(self.data, indices, 0)\n",
    "        y_batch = self.targets[indices]\n",
    "        return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data\n",
    "with np.load(\"notMNIST.npz\") as data :\n",
    "    Data, Target = data [\"images\"], data[\"labels\"]\n",
    "    posClass = 2\n",
    "    negClass = 9\n",
    "    dataIndx = (Target==posClass) + (Target==negClass)\n",
    "    Data = Data[dataIndx]/255.\n",
    "    Target = Target[dataIndx].reshape(-1, 1)\n",
    "    Target[Target==posClass] = 1\n",
    "    Target[Target==negClass] = 0\n",
    "    np.random.seed(521)\n",
    "    randIndx = np.arange(len(Data))\n",
    "    np.random.shuffle(randIndx)\n",
    "    Data, Target = Data[randIndx], Target[randIndx]\n",
    "    trainData, trainTarget = Data[:3500], Target[:3500]\n",
    "    validData, validTarget = Data[3500:3600], Target[3500:3600]\n",
    "    testData, testTarget = Data[3600:], Target[3600:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = np.reshape(trainData, [trainData.shape[0], 28*28])\n",
    "validData = np.reshape(validData, [validData.shape[0], 28*28])\n",
    "testData = np.reshape(testData, [testData.shape[0], 28*28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mse loss function\n",
    "def mse_loss(yhat, target):\n",
    "    loss = tf.reduce_mean(tf.pow(tf.subtract(yhat, target), 2))\n",
    "    loss = tf.div(loss, 2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ques 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr loss: 0.335863\n",
      "epoch: 0.0\n",
      "curr loss: 0.197385\n",
      "epoch: 1.0\n",
      "curr loss: 0.207153\n",
      "epoch: 2.0\n",
      "curr loss: 0.196189\n",
      "epoch: 3.0\n",
      "curr loss: 0.205951\n",
      "epoch: 4.0\n",
      "curr loss: 0.19697\n",
      "epoch: 5.0\n",
      "curr loss: 0.199093\n",
      "epoch: 0.0\n",
      "curr loss: 0.211201\n",
      "epoch: 1.0\n",
      "curr loss: 0.218195\n",
      "epoch: 2.0\n",
      "curr loss: 0.191294\n",
      "epoch: 3.0\n",
      "curr loss: 0.201303\n",
      "epoch: 4.0\n",
      "curr loss: 0.195375\n",
      "epoch: 5.0\n",
      "curr loss: 0.542416\n",
      "epoch: 0.0\n",
      "curr loss: 0.494644\n",
      "epoch: 1.0\n",
      "curr loss: 0.424321\n",
      "epoch: 2.0\n",
      "curr loss: 0.397807\n",
      "epoch: 3.0\n",
      "curr loss: 0.350537\n",
      "epoch: 4.0\n",
      "curr loss: 0.317258\n",
      "epoch: 5.0\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#hyperparameters\n",
    "\n",
    "learning_rates = [0.005, 0.001, 0.0001]\n",
    "# learning_rates = [0.005]\n",
    "mini_batch = 500\n",
    "reg_coeff = 0.0\n",
    "train_iter = 20000\n",
    "train_loss = []\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    train_loss_curr = []\n",
    "    \n",
    "    x = tf.placeholder(tf.float32, shape = [None, 784])\n",
    "    y = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "\n",
    "    w = tf.Variable(np.random.randn())\n",
    "    b = tf.cast(tf.Variable(0), dtype = tf.float32)\n",
    "    yhat = tf.add(tf.multiply(x, w), b)\n",
    "\n",
    "    mse = mse_loss(yhat, y)\n",
    "    regul = tf.multiply(reg_coeff, tf.reduce_mean(tf.square(w)))\n",
    "    cost = tf.add(mse, regul)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(train_iter):\n",
    "#         x_batch, y_batch = tf.train.batch([trainData, trainTarget], mini_batch)\n",
    "        \n",
    "        trainBatchSampler = BatchSampler(trainData, trainTarget, mini_batch)\n",
    "        x_batch, y_batch = trainBatchSampler.get_batch()\n",
    "        \n",
    "        sess.run(optimizer, feed_dict = {x: x_batch, y:y_batch})\n",
    "        w_curr, b_curr, c = sess.run([w, b, cost], feed_dict = {x: x_batch, y:y_batch})\n",
    "        train_loss_curr.append(c)\n",
    "        \n",
    "        if epoch%3500 is 0:\n",
    "            print(\"curr loss:\", c)\n",
    "            print(\"epoch:\", epoch/3500)\n",
    "            \n",
    "    train_loss.append(train_loss_curr)\n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotx = np.linspace(0, train_iter, train_iter)\n",
    "ploty = np.array(train_loss)\n",
    "\n",
    "plt.figure(1)\n",
    "for i in range(ploty.shape[0]):\n",
    "    plt.plot(plotx, ploty[i])\n",
    "\n",
    "plt.savefig(\"linear_ques1.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ques 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr loss: 0.21795\n",
      "epoch: 0.0\n",
      "curr loss: 0.193324\n",
      "epoch: 1.0\n",
      "curr loss: 0.201922\n",
      "epoch: 2.0\n",
      "curr loss: 0.216989\n",
      "epoch: 3.0\n",
      "curr loss: 0.206633\n",
      "epoch: 4.0\n",
      "curr loss: 0.204542\n",
      "epoch: 5.0\n",
      "curr loss: 0.333588\n",
      "epoch: 0.0\n",
      "curr loss: 0.200437\n",
      "epoch: 1.0\n",
      "curr loss: 0.196818\n",
      "epoch: 2.0\n",
      "curr loss: 0.201036\n",
      "epoch: 3.0\n",
      "curr loss: 0.206048\n",
      "epoch: 4.0\n",
      "curr loss: 0.201586\n",
      "epoch: 5.0\n",
      "curr loss: 1.31265\n",
      "epoch: 0.0\n",
      "curr loss: 0.200931\n",
      "epoch: 1.0\n",
      "curr loss: 0.201214\n",
      "epoch: 2.0\n",
      "curr loss: 0.201211\n",
      "epoch: 3.0\n",
      "curr loss: 0.201209\n",
      "epoch: 4.0\n",
      "curr loss: 0.201202\n",
      "epoch: 5.0\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#hyperparameters\n",
    "\n",
    "#best learning rate from previous part\n",
    "learning_rate = 0.005\n",
    "# mini_batch = 500\n",
    "mini_batches = [500, 1500, 3500]\n",
    "reg_coeff = 0.0\n",
    "train_iter = 20000\n",
    "train_loss = []\n",
    "\n",
    "for mini_batch in mini_batches:\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    train_loss_curr = []\n",
    "    \n",
    "    x = tf.placeholder(tf.float32, shape = [None, 784])\n",
    "    y = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "\n",
    "    w = tf.Variable(np.random.randn())\n",
    "    b = tf.cast(tf.Variable(0), dtype = tf.float32)\n",
    "    yhat = tf.add(tf.multiply(x, w), b)\n",
    "\n",
    "    mse = mse_loss(yhat, y)\n",
    "    regul = tf.multiply(reg_coeff, tf.reduce_mean(tf.square(w)))\n",
    "    cost = tf.add(mse, regul)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(train_iter):\n",
    "#         x_batch, y_batch = tf.train.batch([trainData, trainTarget], mini_batch)\n",
    "        \n",
    "        trainBatchSampler = BatchSampler(trainData, trainTarget, mini_batch)\n",
    "        x_batch, y_batch = trainBatchSampler.get_batch()\n",
    "        \n",
    "        sess.run(optimizer, feed_dict = {x: x_batch, y:y_batch})\n",
    "        w_curr, b_curr, c = sess.run([w, b, cost], feed_dict = {x: x_batch, y:y_batch})\n",
    "        train_loss_curr.append(c)\n",
    "        \n",
    "        if epoch%3500 is 0:\n",
    "            print(\"curr loss:\", c)\n",
    "            print(\"epoch:\", epoch/3500)\n",
    "            \n",
    "    train_loss.append(train_loss_curr)\n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotx = np.linspace(0, train_iter, train_iter)\n",
    "ploty = np.array(train_loss)\n",
    "\n",
    "plt.figure(2)\n",
    "for i in range(ploty.shape[0]):\n",
    "    plt.plot(plotx, ploty[i])\n",
    "\n",
    "plt.savefig(\"linear_ques2.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ques 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr loss: 0.47323\n",
      "epoch: 0.0\n",
      "curr loss: 0.210846\n",
      "epoch: 1.0\n",
      "curr loss: 0.197415\n",
      "epoch: 2.0\n",
      "curr loss: 0.195998\n",
      "epoch: 3.0\n",
      "curr loss: 0.201153\n",
      "epoch: 4.0\n",
      "curr loss: 0.208757\n",
      "epoch: 5.0\n",
      "curr loss: 0.221294\n",
      "epoch: 0.0\n",
      "curr loss: 0.200927\n",
      "epoch: 1.0\n",
      "curr loss: 0.198509\n",
      "epoch: 2.0\n",
      "curr loss: 0.205992\n",
      "epoch: 3.0\n",
      "curr loss: 0.211912\n",
      "epoch: 4.0\n",
      "curr loss: 0.201376\n",
      "epoch: 5.0\n",
      "curr loss: 0.663009\n",
      "epoch: 0.0\n",
      "curr loss: 0.222919\n",
      "epoch: 1.0\n",
      "curr loss: 0.229209\n",
      "epoch: 2.0\n",
      "curr loss: 0.210053\n",
      "epoch: 3.0\n",
      "curr loss: 0.213197\n",
      "epoch: 4.0\n",
      "curr loss: 0.213646\n",
      "epoch: 5.0\n",
      "curr loss: 3.40812\n",
      "epoch: 0.0\n",
      "curr loss: 0.250492\n",
      "epoch: 1.0\n",
      "curr loss: 0.239719\n",
      "epoch: 2.0\n",
      "curr loss: 0.233635\n",
      "epoch: 3.0\n",
      "curr loss: 0.256865\n",
      "epoch: 4.0\n",
      "curr loss: 0.242933\n",
      "epoch: 5.0\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#hyperparameters\n",
    "\n",
    "learning_rate = 0.005\n",
    "mini_batch = 500\n",
    "# reg_coeff = 0.0\n",
    "reg_coeffs = [0.0, 0.001, 0.1, 1.0]\n",
    "train_iter = 20000\n",
    "train_loss = []\n",
    "\n",
    "for reg_coeff in reg_coeffs:\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    train_loss_curr = []\n",
    "    \n",
    "    x = tf.placeholder(tf.float32, shape = [None, 784])\n",
    "    y = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "\n",
    "    w = tf.Variable(np.random.randn())\n",
    "    b = tf.cast(tf.Variable(0), dtype = tf.float32)\n",
    "    yhat = tf.add(tf.multiply(x, w), b)\n",
    "\n",
    "    mse = mse_loss(yhat, y)\n",
    "    regul = tf.multiply(reg_coeff, tf.reduce_mean(tf.square(w)))\n",
    "    cost = tf.add(mse, regul)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(train_iter):\n",
    "#         x_batch, y_batch = tf.train.batch([trainData, trainTarget], mini_batch)\n",
    "        \n",
    "        trainBatchSampler = BatchSampler(trainData, trainTarget, mini_batch)\n",
    "        x_batch, y_batch = trainBatchSampler.get_batch()\n",
    "        \n",
    "        sess.run(optimizer, feed_dict = {x: x_batch, y:y_batch})\n",
    "        w_curr, b_curr, c = sess.run([w, b, cost], feed_dict = {x: x_batch, y:y_batch})\n",
    "        train_loss_curr.append(c)\n",
    "        \n",
    "        if epoch%3500 is 0:\n",
    "            print(\"curr loss:\", c)\n",
    "            print(\"epoch:\", epoch/3500)\n",
    "            \n",
    "    train_loss.append(train_loss_curr)\n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotx = np.linspace(0, train_iter, train_iter)\n",
    "ploty = np.array(train_loss)\n",
    "\n",
    "plt.figure(3)\n",
    "for i in range(ploty.shape[0]):\n",
    "    plt.plot(plotx, ploty[i])\n",
    "\n",
    "plt.savefig(\"linear_ques3.png\")\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
