{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchSampler(object):\n",
    "    '''\n",
    "    A (very) simple wrapper to randomly sample batches without replacement.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, data, targets, batch_size):\n",
    "        self.num_points = data.shape[0]\n",
    "        self.features = data.shape[1]\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.batch_size = batch_size\n",
    "        self.indices = np.arange(self.num_points)\n",
    "\n",
    "    def random_batch_indices(self, m=None):\n",
    "        if m is None:\n",
    "            indices = np.random.choice(self.indices, self.batch_size, replace=False)\n",
    "        else:\n",
    "            indices = np.random.choice(self.indices, m, replace=False)\n",
    "        return indices \n",
    "\n",
    "    def get_batch(self, m=None):\n",
    "        '''\n",
    "        Get a random batch without replacement from the dataset.\n",
    "        If m is given the batch will be of size m. \n",
    "        Otherwise will default to the class initialized value.\n",
    "        '''\n",
    "        indices = self.random_batch_indices(m)\n",
    "        X_batch = np.take(self.data, indices, 0)\n",
    "        y_batch = self.targets[indices]\n",
    "        return X_batch, y_batch  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotFig(_num, _dim, y , addInfo, title=\"default\", xLabel=\"xlabel\", yLabel=\"yLabel\", plotLabel =\"plotLabel\" ):\n",
    "    x = np.linspace(0, _dim, num=_dim)\n",
    "   \n",
    "    \n",
    "    y = np.array(y)\n",
    "    print(y.shape)\n",
    "    plt.figure(_num)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xLabel)\n",
    "    plt.ylabel(yLabel)\n",
    "    for i in range(y.shape[0]):\n",
    "        plt.plot(x, y[i], label = plotLabel + str(addInfo[i]))\n",
    "        \n",
    "    plt.legend()\n",
    "    plt.savefig( title + str(_num) + \".png\")\n",
    "    plt.close()\n",
    "    plt.clf()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3745, 28, 28)\n",
      "Data binary class Loaded\n",
      "-------------------------------\n",
      "y_hat (100, 1)\n",
      "target (100, 1)\n",
      "y_hat (145, 1)\n",
      "target (145, 1)\n",
      "in linear normal eqn\n",
      "validErr 0.0226958099498 testErr 0.0369294998731\n",
      "****** START Q1.1 *****\n",
      "y_hat (?, 1)\n",
      "target (?, 1)\n",
      "mseerRor 1 Tensor(\"truediv:0\", shape=(), dtype=float64)\n",
      "regTerm Tensor(\"Mul_1:0\", shape=(), dtype=float64)\n",
      "mseerRor Tensor(\"Add:0\", shape=(), dtype=float64)\n",
      "learningrate =  0.005\n",
      "current err 0.511327268798\n",
      "epoch  0.0\n",
      "current err 0.0256642873419\n",
      "epoch  1.0\n",
      "current err 0.018307179221\n",
      "epoch  2.0\n",
      "current err 0.0172149878759\n",
      "epoch  3.0\n",
      "current err 0.0179809822094\n",
      "epoch  4.0\n",
      "current err 0.0155519387488\n",
      "epoch  5.0\n",
      "y_hat (?, 1)\n",
      "target (?, 1)\n",
      "mseerRor 1 Tensor(\"truediv:0\", shape=(), dtype=float64)\n",
      "regTerm Tensor(\"Mul_1:0\", shape=(), dtype=float64)\n",
      "mseerRor Tensor(\"Add:0\", shape=(), dtype=float64)\n",
      "learningrate =  0.001\n",
      "current err 2.03010084713\n",
      "epoch  0.0\n",
      "current err 0.0573251676646\n",
      "epoch  1.0\n",
      "current err 0.0356191352479\n",
      "epoch  2.0\n",
      "current err 0.0321442127509\n",
      "epoch  3.0\n",
      "current err 0.0274051440542\n",
      "epoch  4.0\n",
      "current err 0.0251540700949\n",
      "epoch  5.0\n",
      "y_hat (?, 1)\n",
      "target (?, 1)\n",
      "mseerRor 1 Tensor(\"truediv:0\", shape=(), dtype=float64)\n",
      "regTerm Tensor(\"Mul_1:0\", shape=(), dtype=float64)\n",
      "mseerRor Tensor(\"Add:0\", shape=(), dtype=float64)\n",
      "learningrate =  0.0001\n",
      "current err 5.07769535604\n",
      "epoch  0.0\n",
      "current err 0.139219499169\n",
      "epoch  1.0\n",
      "current err 0.103671293489\n",
      "epoch  2.0\n",
      "current err 0.080692301929\n",
      "epoch  3.0\n",
      "current err 0.0715218752912\n",
      "epoch  4.0\n",
      "current err 0.0676285129146\n",
      "epoch  5.0\n",
      "train done\n",
      "(3, 20000)\n",
      "****** START Q1.2 *****\n",
      "y_hat (?, 1)\n",
      "target (?, 1)\n",
      "mseerRor 1 Tensor(\"truediv:0\", shape=(), dtype=float64)\n",
      "regTerm Tensor(\"Mul_1:0\", shape=(), dtype=float64)\n",
      "mseerRor Tensor(\"Add:0\", shape=(), dtype=float64)\n",
      "batchSize 500\n",
      "current err 0.35886629695\n",
      "epoch  0.0\n",
      "current err 0.0265437548491\n",
      "epoch  1.0\n",
      "current err 0.0156061202692\n",
      "epoch  2.0\n",
      "current err 0.0165702459516\n",
      "epoch  3.0\n",
      "current err 0.0144719776824\n",
      "epoch  4.0\n",
      "current err 0.0172596835152\n",
      "epoch  5.0\n",
      "time  26.80998396873474 batchsize 500\n",
      "y_hat (?, 1)\n",
      "target (?, 1)\n",
      "mseerRor 1 Tensor(\"truediv:0\", shape=(), dtype=float64)\n",
      "regTerm Tensor(\"Mul_1:0\", shape=(), dtype=float64)\n",
      "mseerRor Tensor(\"Add:0\", shape=(), dtype=float64)\n",
      "batchSize 1500\n",
      "current err 0.970953747114\n",
      "epoch  0.0\n",
      "current err 0.0255847352112\n",
      "epoch  1.0\n",
      "current err 0.0211866647579\n",
      "epoch  2.0\n",
      "current err 0.0161374072587\n",
      "epoch  3.0\n",
      "current err 0.0161242402654\n",
      "epoch  4.0\n",
      "current err 0.0167087204339\n",
      "epoch  5.0\n",
      "time  127.8345160484314 batchsize 1500\n",
      "y_hat (?, 1)\n",
      "target (?, 1)\n",
      "mseerRor 1 Tensor(\"truediv:0\", shape=(), dtype=float64)\n",
      "regTerm Tensor(\"Mul_1:0\", shape=(), dtype=float64)\n",
      "mseerRor Tensor(\"Add:0\", shape=(), dtype=float64)\n",
      "batchSize 3500\n",
      "current err 0.486198581744\n",
      "epoch  0.0\n",
      "current err 0.0251875041809\n",
      "epoch  1.0\n",
      "current err 0.019310256368\n",
      "epoch  2.0\n",
      "current err 0.0169992764538\n",
      "epoch  3.0\n",
      "current err 0.0157039814335\n",
      "epoch  4.0\n",
      "current err 0.014843944671\n",
      "epoch  5.0\n",
      "time  285.0699210166931 batchsize 3500\n",
      "trainLosssAll [0.015550678870973982, 0.012597873600062917, 0.01437974168172089]\n",
      "y_hat (?, 1)\n",
      "target (?, 1)\n",
      "mseerRor 1 Tensor(\"truediv:0\", shape=(), dtype=float64)\n",
      "regTerm Tensor(\"Mul_1:0\", shape=(), dtype=float64)\n",
      "mseerRor Tensor(\"Add:0\", shape=(), dtype=float64)\n",
      "learningrate =  0.005\n",
      "current err 6.99622634107\n",
      "epoch  0.0\n",
      "current err 0.0193136353959\n",
      "epoch  1.0\n",
      "current err 0.0189787729258\n",
      "epoch  2.0\n",
      "current err 0.0134169998473\n",
      "epoch  3.0\n",
      "current err 0.0166917789142\n",
      "epoch  4.0\n",
      "current err 0.012447359967\n",
      "epoch  5.0\n",
      "y_hat (?, 1)\n",
      "target (?, 1)\n",
      "mseerRor 1 Tensor(\"truediv:0\", shape=(), dtype=float64)\n",
      "regTerm Tensor(\"Mul_1:0\", shape=(), dtype=float64)\n",
      "mseerRor Tensor(\"Add:0\", shape=(), dtype=float64)\n",
      "learningrate =  0.005\n",
      "current err 1.38271106157\n",
      "epoch  0.0\n",
      "current err 0.0253735930553\n",
      "epoch  1.0\n",
      "current err 0.0198953347139\n",
      "epoch  2.0\n",
      "current err 0.0174318068351\n",
      "epoch  3.0\n",
      "current err 0.0162250832518\n",
      "epoch  4.0\n",
      "current err 0.0128963384246\n",
      "epoch  5.0\n",
      "y_hat (?, 1)\n",
      "target (?, 1)\n",
      "mseerRor 1 Tensor(\"truediv:0\", shape=(), dtype=float64)\n",
      "regTerm Tensor(\"Mul_1:0\", shape=(), dtype=float64)\n",
      "mseerRor Tensor(\"Add:0\", shape=(), dtype=float64)\n",
      "learningrate =  0.005\n",
      "current err 1.70528875761\n",
      "epoch  0.0\n",
      "current err 0.0235096470198\n",
      "epoch  1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ec1846f4e566>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"****** START Q1.2 *****\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[0mrunLinearGraphPart2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainTarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m     \u001b[0mrunLinearGraphPart3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainTarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidTarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestTarget\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-ec1846f4e566>\u001b[0m in \u001b[0;36mrunLinearGraphPart3\u001b[0;34m(trainData, trainTarget, validData, validTarget, testData, testTarget)\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m3500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m             \u001b[0merrValid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmseError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalidData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_target\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalidTarget\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m             \u001b[0merrTest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmseError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtestData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_target\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtestTarget\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0merrValidArr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrValid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ca7dcf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def arrFlatten(arr):\n",
    "    \n",
    "    print(arr.shape)\n",
    "\n",
    "    dataDim1, dum1, dum2 = arr.shape\n",
    "    arr = np.reshape(arr, [ dataDim1 ,784 ])\n",
    "    return arr\n",
    "\n",
    "\n",
    "def loadBinData(linEqn = False):\n",
    "# import binary NOTMIST data set\n",
    "    with np.load(\"notMNIST.npz\") as data :\n",
    "        Data, Target = data [\"images\"], data[\"labels\"]\n",
    "        posClass = 2\n",
    "        negClass = 9\n",
    "        dataIndx = (Target==posClass) + (Target==negClass)\n",
    "        Data = Data[dataIndx]/255.\n",
    "        Target = Target[dataIndx].reshape(-1, 1)\n",
    "        Target[Target==posClass] = 1\n",
    "        Target[Target==negClass] = 0\n",
    "        \n",
    "        Data = arrFlatten(Data)\n",
    "        \n",
    "        if linEqn:\n",
    "            Data = np.concatenate((np.ones((Data.shape[0], 1)),Data),axis=1)\n",
    "        \n",
    "        \n",
    "        np.random.seed(521)\n",
    "        randIndx = np.arange(len(Data))\n",
    "        np.random.shuffle(randIndx)\n",
    "        Data, Target = Data[randIndx], Target[randIndx]\n",
    "        trainData, trainTarget = Data[:3500], Target[:3500]\n",
    "        validData, validTarget = Data[3500:3600], Target[3500:3600]\n",
    "        testData, testTarget = Data[3600:], Target[3600:]\n",
    "        \n",
    "    print(\"Data binary class Loaded\")\n",
    "    print(\"-------------------------------\")\n",
    "    return trainData, trainTarget,validData, validTarget,\\\n",
    "        testData, testTarget\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def linearMSE(y_hat, target):\n",
    "    '''\n",
    "    y_hat, target will be fed\n",
    "    '''\n",
    "    print(\"y_hat\",  y_hat.shape)\n",
    "    print(\"target\", target.shape)\n",
    "    \n",
    "    y_hat = tf.convert_to_tensor(y_hat)\n",
    "    target = tf.convert_to_tensor(target)\n",
    "    \n",
    "    target = tf.cast(target, dtype = 'float64')\n",
    "    se_mat = tf.square(tf.subtract(y_hat, target))\n",
    "    #print(\"msemst\", mse_mat)\n",
    "    mse_mat = tf.reduce_mean(se_mat)\n",
    "\n",
    "    loss = tf.reduce_mean(mse_mat)\n",
    "\n",
    "    loss = loss/2.0 #tf.div(loss, tf.constant(2.0))\n",
    "    #print(mse_mat.eval())\n",
    "\n",
    "    return loss  \n",
    "\n",
    "def accuracy(y_hat, target, classType = 0):\n",
    "    if classType == 0:\n",
    "        correctCases = tf.equal(tf.cast(tf.greater_equal(y_hat, 0.5), tf.float64), tf.floor(target))\n",
    "    else:\n",
    "        correctCases = tf.equal(tf.argmax(y_hat, 1), tf.argmax(target, 1))\n",
    "\n",
    "    accuracy = tf.reduce_mean(tf.cast(correctCases, dtype=\"float\"))\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "    \n",
    "def fit_regression(X,Y,  validX, validY, testX, testY):\n",
    "    #TODO: implement linear regression\n",
    "    # Remember to use np.linalg.solve instead of inverting!\n",
    "    #X = np.concatenate((np.ones((X.shape[0],1)),X),axis=1) #add constant one feature - no bias needed\n",
    "    xtx = np.dot(np.transpose(X), X)\n",
    "    xty = np.dot(np.transpose(X), Y)\n",
    "    w = np.linalg.solve(xtx, xty)\n",
    "    #w = np.linalg.inv(xtx, xty)\n",
    "    \n",
    "    testYhat = np.dot(testX, w)\n",
    "    validYhat = np.dot(validX, w)\n",
    "    #print(testYhat)\n",
    "    \n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.InteractiveSession()\n",
    "    sess.run(init)\n",
    "    validErr = linearMSE(validYhat, validY)\n",
    "    testErr = linearMSE(testYhat, testY)\n",
    "    print(\"in linear normal eqn\")\n",
    "    print(\"validErr\", validErr.eval(), \"testErr\", testErr.eval())\n",
    "\n",
    "\n",
    "\n",
    "def linearNormalEqn(trainData, trainTarget):\n",
    "    y_target = tf.cast(trainTarget, dtype='float32')\n",
    "    \n",
    "    onesX = tf.ones(shape=tf.stack([tf.shape(trainData)[0], 1]))\n",
    "    appendOnesX = tf.concat([trainData, onesX], 1)\n",
    "    w_star = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(tf.transpose(appendOnesX),\\\n",
    "                                                appendOnesX)), tf.transpose(appendOnesX)), y_target)\n",
    "    \n",
    "    print(w_star)\n",
    "    pred_y = tf.matmul(appendOnesX, w_star)\n",
    "    print(pred_y)\n",
    "    y_hat = tf.cast(tf.greater_equal(pred_y, 0.5), tf.float32) #float\n",
    "    print(\"######################\")\n",
    "    print(\"linear normal equation\")\n",
    "    mseError = linearMSE(y_hat, trainTarget)\n",
    "    print(\"mse error\", mseError)\n",
    "    \n",
    "    return mseError\n",
    "'''\n",
    "def linearNormalEqn(trainData, trainTarget):\n",
    "\n",
    "    X = tf.placeholder(tf.float32, shape=[None, 784], name='dataX')\n",
    "    b = tf.Variable(0.0, name='biases')\n",
    "    y_target = tf.placeholder(tf.float32, shape=[None, 1], name='targetY')\n",
    "    \n",
    "    onesX = tf.ones(shape=(1, 784))   #(shape=tf.stack([tf.shape(X)[0], 1]))\n",
    "    appendOnesX = tf.concat([X, onesX], 0) #1 for offset b\n",
    "    print(appendOnesX)\n",
    "    w_star = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(tf.transpose(appendOnesX),\\\n",
    "                                                appendOnesX)), tf.transpose(appendOnesX)), y_target)\n",
    "\n",
    "    print(w_star)\n",
    "    pred_y = tf.matmul(appendOnesX, w_star)\n",
    "    print(pred_y)\n",
    "    y_hat = tf.cast(tf.greater_equal(pred_y, 0.5), tf.float32) #float to bool to float 1 or 0\n",
    "    print(y_hat)\n",
    "    mseError = linearMSE(y_hat, trainTarget)\n",
    "    \n",
    "    \n",
    "    #finish build graph\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.InteractiveSession()\n",
    "    sess.run(init)\n",
    "    errTrain = sess.run([mseError], feed_dict={X: trainData, y_target: trainTarget})\n",
    "\n",
    "    \n",
    "    print(\"######################\")\n",
    "    print(\"linear normal equation\")\n",
    "    print(\"mse error\", mse)\n",
    "    return X, y_target, errTrain\n",
    "\n",
    "\n",
    "'''\n",
    "def linearBuildGraph(_regLambda, _learningRate, gd = True):\n",
    "    '''\n",
    "    Input: _data is x in the equation, dim by 784 flattened tensor\n",
    "       _target is y in the equaion\n",
    "       _regLambda is the wegithed decay coeff\n",
    "       _learningRate is the epsilon\n",
    "    '''\n",
    "    _regLambda = tf.cast(_regLambda, dtype = tf.float64)\n",
    "\n",
    "    #declare using a placeholder, feed in _data and _target to x ,y \n",
    "    #x_dim, dum1 =_data.get_shape().as_list()\n",
    "    X = tf.placeholder(tf.float64, shape=[None, 784], name='dataX')\n",
    "    # W initialize to a gaussian distr, honestly anything would work\n",
    "    W = tf.Variable(tf.truncated_normal(shape=[784, 1], stddev=0.1), name='weights')\n",
    "    W = tf.cast(W, dtype=tf.float64)\n",
    "    b = tf.Variable(0.0, name='biases')\n",
    "    b = tf.cast(b, dtype=tf.float64)\n",
    "\n",
    "    y_target = tf.placeholder(tf.float64, shape=[None, 1], name='targetY')\n",
    "    \n",
    "    #compute the current y_hat\n",
    "    y_hat =  tf.matmul(X, W) + b\n",
    "    #compute the current loss\n",
    "    \n",
    "    \n",
    "    mseCurr = linearMSE(y_hat, y_target)\n",
    "    print(\"mseerRor 1\", mseCurr)\n",
    "\n",
    "    #compute the decay/regularization term\n",
    "    regTerm =tf.multiply(tf.constant(0.50, dtype = tf.float64), tf.multiply(_regLambda, tf.reduce_mean(tf.square(W))))\n",
    "    \n",
    "    print(\"regTerm\", regTerm)\n",
    "    mseCurr = tf.add(mseCurr, regTerm)\n",
    "    print(\"mseerRor\", mseCurr)\n",
    "    \n",
    "    \n",
    "    if gd:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate = _learningRate)\n",
    "    else:\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate = _learningRate)\n",
    "    \n",
    "    train = optimizer.minimize(loss=mseCurr)\n",
    "\n",
    "    return W, b, mseCurr, y_hat, X, y_target, train\n",
    "    \n",
    "\n",
    "def runLinearGraphPart1(trainData, trainTarget ):\n",
    "    \n",
    "    '''\n",
    "    Input: _data,\n",
    "           _target,\n",
    "           _numIters\n",
    "    Output:\n",
    "           required accuracy/epoch plots\n",
    "           \n",
    "    '''\n",
    "    \n",
    "    regLambda = 0.0\n",
    "    learningRateArr = [0.005, 0.001, 0.0001]\n",
    "    numIter = 20000\n",
    "    numEpoch =int(np.ceil(20000/7))\n",
    "    batchSize = 500\n",
    "    epochTrainSize = 3500\n",
    "    trainLossAll = []\n",
    "    \n",
    "    for learningRate in learningRateArr:\n",
    "        trainLossLR = []\n",
    "        tf.reset_default_graph()\n",
    "        W, b, mseError, y_hat, X, y_target, train = linearBuildGraph(regLambda, learningRate)\n",
    "    \n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess = tf.InteractiveSession()\n",
    "        sess.run(init)\n",
    "        initialW = sess.run(W)  \n",
    "        initialb = sess.run(b)            \n",
    "        #training model and iter through batches\n",
    "        print(\"learningrate = \", learningRate)\n",
    "        \n",
    "        for i in range(numIter):\n",
    "            trainBatchSampler = BatchSampler(trainData, trainTarget, batchSize)\n",
    "            dataBatch, targetBatch = trainBatchSampler.get_batch()\n",
    "            #dataBatch = tf.stack(dataBatch)\n",
    "            #targetBatch = tf.stack(targetBatch)\n",
    "            currentW, currentb, errTrain, y_predict, trainModel = sess.run([W, b, mseError, y_hat, train], feed_dict={X: dataBatch, y_target: targetBatch})\n",
    "            trainLossLR.append(errTrain)\n",
    "            if i%3500 == 0:\n",
    "                print(\"current err\", errTrain)\n",
    "                print(\"epoch \", i/3500)\n",
    "        trainLossAll.append(trainLossLR)\n",
    "        \n",
    "    print(\"train done\")\n",
    "    plotFig(1, numIter, trainLossAll, learningRateArr,  title = \"loss vs number of epoches\",\\\n",
    "            plotLabel=\"learning rate\")\n",
    "    \n",
    "    \n",
    "def runLinearGraphPart2(trainData, trainTarget ):\n",
    "    \n",
    "    '''\n",
    "    Input: _data,\n",
    "           _target,\n",
    "           _numIters\n",
    "    Output:required accuracy/epoch plots\n",
    "           \n",
    "           \n",
    "    '''\n",
    "    \n",
    "    regLambda = 0.0\n",
    "    learningRate = 0.005 #chosen from part1\n",
    "    numIter = 20000\n",
    "    numEpoch =int(np.ceil(20000/7))\n",
    "    batchSizeArr = [500, 1500, 3500]\n",
    "    epochTrainSize = 3500\n",
    "    trainLossAll = []\n",
    "    \n",
    "    for batchSize in batchSizeArr:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        trainLossLR = []\n",
    "        tf.reset_default_graph()\n",
    "        W, b, mseError, y_hat, X, y_target, train = linearBuildGraph(regLambda, learningRate)\n",
    "    \n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess = tf.InteractiveSession()\n",
    "        sess.run(init)\n",
    "        initialW = sess.run(W)  \n",
    "        initialb = sess.run(b)\n",
    "        \n",
    "        print(\"batchSize\", batchSize)\n",
    "        for i in range(numIter):\n",
    "            trainBatchSampler = BatchSampler(trainData, trainTarget, batchSize)\n",
    "            dataBatch, targetBatch = trainBatchSampler.get_batch()\n",
    "            #dataBatch = tf.stack(dataBatch)\n",
    "            #targetBatch = tf.stack(targetBatch)\n",
    "            currentW, currentb, errTrain, y_predict, trainModel = sess.run([W, b, mseError, y_hat, train], feed_dict={X: dataBatch, y_target: targetBatch})\n",
    "            #trainLossLR.append(errTrain)\n",
    "            if i%3500 == 0:\n",
    "                print(\"current err\", errTrain)\n",
    "                print(\"epoch \", i/3500)\n",
    "        \n",
    "        trainLossAll.append(errTrain)\n",
    "        end = time.time()\n",
    "        elapsed = end - start_time\n",
    "        print(\"time \", elapsed, \"batchsize\", batchSize )\n",
    "    print(\"trainLosssAll\", trainLossAll)    \n",
    "\n",
    "    \n",
    "def runLinearGraphPart3(trainData, trainTarget, validData, validTarget,testData, testTarget):\n",
    "    \n",
    "    '''\n",
    "    Input: _data,\n",
    "           _target,\n",
    "           _numIters\n",
    "    Output:\n",
    "           Lambda results\n",
    "           \n",
    "    '''\n",
    "    \n",
    "    regLambdaArr = [0.0, 0.001, 0.1, 1.0]\n",
    "    learningRate = 0.005\n",
    "    numIter = 20000\n",
    "    numEpoch =int(np.ceil(20000/7))\n",
    "    batchSize = 500\n",
    "    epochTrainSize = 3500\n",
    "    errTestAll = []\n",
    "    errValidAll = []\n",
    "    \n",
    "    for regLambda in regLambdaArr:\n",
    "        errValidArr = []\n",
    "        errTestArr = []\n",
    "        tf.reset_default_graph()\n",
    "        W, b, mseError, y_hat, X, y_target, train = linearBuildGraph(regLambda, learningRate)\n",
    "    \n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess = tf.InteractiveSession()\n",
    "        sess.run(init)\n",
    "        initialW = sess.run(W)  \n",
    "        initialb = sess.run(b)            \n",
    "        #training model and iter through batches\n",
    "        print(\"learningrate = \", learningRate)\n",
    "        for i in range(numIter):\n",
    "            trainBatchSampler = BatchSampler(trainData, trainTarget, batchSize)\n",
    "            dataBatch, targetBatch = trainBatchSampler.get_batch()\n",
    "            #dataBatch = tf.stack(dataBatch)\n",
    "            #targetBatch = tf.stack(targetBatch)\n",
    "            currentW, currentb, errTrain, y_predict, trainModel = sess.run([W, b, mseError, y_hat, train], feed_dict={X: dataBatch, y_target: targetBatch})\n",
    "            if i%3500 == 0:\n",
    "                print(\"current err\", errTrain)\n",
    "                print(\"epoch \", i/3500)\n",
    "        \n",
    "            errValid = sess.run(mseError, feed_dict={X: validData, y_target: validTarget})\n",
    "            errTest = sess.run(mseError, feed_dict={X: testData, y_target: testTarget})\n",
    "            errValidArr.append(errValid)\n",
    "            errTestArr.append(errTest)\n",
    "        \n",
    "        errValidAll.append(errValidArr)\n",
    "        errTestAll.append(errTestArr)\n",
    "    \n",
    "    errValidAll = np.array(errValidAll)\n",
    "    errTestAll = np.array(errTestAll)\n",
    "    #print(errValidAll)\n",
    "    for i in range(errValidAll.shape[0]):\n",
    "        best = np.amin(errValidAll[i])\n",
    "        print(\"bset err valid \",best, \"lambda\", regLambdaArr[i])\n",
    "    \n",
    "    for i in range(errTestAll.shape[0]):\n",
    "        best = np.amin(errTestAll[i])\n",
    "        print(\"bset err test \",best, \"lambda\", regLambdaArr[i])\n",
    "    \n",
    "\n",
    "\n",
    "def runQ2Part3Linear(trainData, trainTarget, validData, validTarget,testData, testTarget):\n",
    "    '''\n",
    "    labmda = 0\n",
    "    n = 0.001\n",
    "    adam optimizer for linear\n",
    "    '''\n",
    "    regLambda = 0.0\n",
    "    learningRate = 0.001\n",
    "    learningRateArr = [0.001] #just for plotting \n",
    "\n",
    "    numIter = 5000\n",
    "    numEpoch =int(np.ceil(20000/7))\n",
    "    batchSize = 500\n",
    "    epochTrainSize = 3500 #for training data\n",
    "    trainLossAll = []\n",
    "\n",
    "    trainLossLR = []\n",
    "    tf.reset_default_graph()\n",
    "    W, b, crossEntropyErrorCurr, y_hat, X, y_target, train = linearBuildGraph(regLambda, learningRate, False)\n",
    "    #y_hat_mse, target_mse, mseLoss = linearMSE()\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.InteractiveSession()\n",
    "    sess.run(init)\n",
    "    initialW = sess.run(W)  \n",
    "    initialb = sess.run(b)            \n",
    "    #training model and iter through batches\n",
    "    print(\"learningrate = \", learningRate)\n",
    "    trainBatchSampler = BatchSampler(trainData, trainTarget, batchSize)\n",
    "\n",
    "    for i in range(numIter):\n",
    "        dataBatch, targetBatch = trainBatchSampler.get_batch()\n",
    "        #dataBatch = tf.stack(dataBatch)\n",
    "        #targetBatch = tf.stack(targetBatch)\n",
    "        currentW, currentb, errTrain, y_predict, trainModel = sess.run([W, b, crossEntropyErrorCurr, y_hat, train], feed_dict={X: dataBatch, y_target: targetBatch})\n",
    "        trainLossLR.append(errTrain)\n",
    "        #mseLoss = linearMSE()\n",
    "        if i%3500 == 0:\n",
    "            print(\"current err\", errTrain)\n",
    "            print(\"epoch \", i/3500)\n",
    "        \n",
    "    trainLossAll.append(trainLossLR)\n",
    "    \n",
    "    print(\"train done\")\n",
    "    plotFig(4, numIter, trainLossAll, learningRateArr,  title = \"q2-3 Adam Opt lambda = 0 linear loss vs number of epoches\",\\\n",
    "            plotLabel=\"learning rate\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "if __name__ == '__main__':  \n",
    "        \n",
    "\n",
    "    #trainTarget = arrFlatten(trainTarget)\n",
    "    trainData, trainTarget, validData, validTarget,testData, testTarget = loadBinData(False)\n",
    "    \n",
    "    \n",
    "    #data is (3500, 28, 28)\n",
    "    #the label [1] or [0] is stored in target\n",
    "\n",
    "    fit_regression(trainData, trainTarget, validData, validTarget,testData, testTarget)\n",
    "\n",
    "    \n",
    "    #trainData = arrFlatten(trainData)\n",
    "    #validData = arrFlatten(validData)\n",
    "    #testData = arrFlatten(testData)\n",
    "    print(\"****** START Q1.1 *****\")\n",
    "    runLinearGraphPart1(trainData, trainTarget)\n",
    "    print(\"****** START Q1.2 *****\")\n",
    "    runLinearGraphPart2(trainData, trainTarget)\n",
    "    runLinearGraphPart3(trainData, trainTarget, validData, validTarget,testData, testTarget )\n",
    "\n",
    "    \n",
    "    print(\"*********START Q2 PART 3 LINEAR*******\")\n",
    "    runQ2Part3Linear(trainData, trainTarget, validData, validTarget,testData, testTarget)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "time  28.17647886276245 batchsize 500\n",
    "time  142.55758595466614 batchsize 1500\n",
    "time  341.4439833164215 batchsize 3500\n",
    "trainLosssAll [0.013990995, 0.015074042, 0.014701741]\n",
    "\n",
    "bset err valid  0.0174993 lambda 0.0\n",
    "bset err valid  0.0200263 lambda 0.001\n",
    "bset err valid  0.019381 lambda 0.1\n",
    "bset err valid  0.0181959 lambda 1.0\n",
    "bset err test  0.0212588 lambda 0.0\n",
    "bset err test  0.0222249 lambda 0.001\n",
    "bset err test  0.0217733 lambda 0.1\n",
    "bset err test  0.0242665 lambda 1.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
